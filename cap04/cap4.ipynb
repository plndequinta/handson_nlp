{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformando Texto em Estruturas de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Computadores só \"entendem\" números. Por isso "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words em ação\n",
    "\n",
    "@author: Aman Kedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\luizf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\luizf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentenças"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"We are reading about Natural Language Processing Here\",\n",
    "            \"Natural Language Processing making computers comprehend language data\",\n",
    "            \"The field of Natural Language Processing is evolving everyday\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    We are reading about Natural Language Processi...\n",
       "1    Natural Language Processing making computers c...\n",
       "2    The field of Natural Language Processing is ev...\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.Series(sentences)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processamento de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 1: Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(corpus, keep_list):\n",
    "    '''\n",
    "    Purpose : Function to keep only alphabets, digits and certain words (punctuations, qmarks, tabs etc. removed)\n",
    "    \n",
    "    Input : Takes a text corpus, 'corpus' to be cleaned along with a list of words, 'keep_list', which have to be retained\n",
    "            even after the cleaning process\n",
    "    \n",
    "    Output : Returns the cleaned text corpus\n",
    "    \n",
    "    '''\n",
    "    cleaned_corpus = pd.Series(dtype=str)\n",
    "    for row in corpus:\n",
    "        qs = []\n",
    "        for word in row.split():\n",
    "            if word not in keep_list:\n",
    "                p1 = re.sub(pattern='[^a-zA-Z0-9]',repl=' ',string=word)\n",
    "                p1 = p1.lower()\n",
    "                qs.append(p1)\n",
    "            else : qs.append(word)\n",
    "        cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
    "    return cleaned_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    srs   vamos come ar representando um documento...\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto = pd.Series(['Srs., vamos começar representando um documento por meio da frequência das suas palavras!'])\n",
    "r = text_clean(texto, [])\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['srs   vamos come ar representando um documento por meio da frequ ncia das suas palavras ']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 2: Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_removal(corpus):\n",
    "    wh_words = ['who', 'what', 'when', 'why', 'how', 'which', 'where', 'whom']\n",
    "    stop = set(stopwords.words('english'))\n",
    "    for word in wh_words:\n",
    "        stop.remove(word)\n",
    "    corpus = [[x for x in x.split() if x not in stop] for x in corpus]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 3: Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(corpus):\n",
    "    \"\"\"Lemmatize verbs\n",
    "\n",
    "    Args:\n",
    "        corpus (2d iterable): tokens to lemmatize, \n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "    lem = WordNetLemmatizer()\n",
    "    corpus = [[lem.lemmatize(x, pos = 'v') for x in x] for x in corpus]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['We', 'are', 'reading', 'about', 'Natural', 'Language', 'Processing', 'Here']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['We', 'be', 'read', 'about', 'Natural', 'Language', 'Processing', 'Here']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entrada = [corpus[0].split()]\n",
    "saida = lemmatize(entrada)\n",
    "print(entrada)\n",
    "saida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 4: Stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(corpus, stem_type = None):\n",
    "    if stem_type == 'snowball':\n",
    "        stemmer = SnowballStemmer(language = 'english')\n",
    "        corpus = [[stemmer.stem(x) for x in x] for x in corpus]\n",
    "    else :\n",
    "        stemmer = PorterStemmer()\n",
    "        corpus = [[stemmer.stem(x) for x in x] for x in corpus]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['We', 'are', 'reading', 'about', 'Natural', 'Language', 'Processing', 'Here']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['we', 'are', 'read', 'about', 'natur', 'languag', 'process', 'here']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# usando o stem padrão (PorterStemmer)\n",
    "entrada = [corpus[0].split()]\n",
    "saida = stem(entrada)\n",
    "print(entrada)\n",
    "saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['We', 'are', 'reading', 'about', 'Natural', 'Language', 'Processing', 'Here']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['we', 'are', 'read', 'about', 'natur', 'languag', 'process', 'here']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# usando o stem snowball\n",
    "entrada = [corpus[0].split()]\n",
    "saida = stem(entrada, 'snowball')\n",
    "print(entrada)\n",
    "saida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(corpus, keep_list, cleaning = True, stemming = False, stem_type = None, lemmatization = False, remove_stopwords = True):\n",
    "    '''\n",
    "    Purpose : Function to perform all pre-processing tasks (cleaning, stemming, lemmatization, stopwords removal etc.)\n",
    "    \n",
    "    Input : \n",
    "    'corpus' - Text corpus on which pre-processing tasks will be performed\n",
    "    'keep_list' - List of words to be retained during cleaning process\n",
    "    'cleaning', 'stemming', 'lemmatization', 'remove_stopwords' - Boolean variables indicating whether a particular task should \n",
    "                                                                  be performed or not\n",
    "    'stem_type' - Choose between Porter stemmer or Snowball(Porter2) stemmer. Default is \"None\", which corresponds to Porter\n",
    "                  Stemmer. 'snowball' corresponds to Snowball Stemmer\n",
    "    \n",
    "    Note : Either stemming or lemmatization should be used. There's no benefit of using both of them together\n",
    "    \n",
    "    Output : Returns the processed text corpus\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if cleaning == True:\n",
    "        corpus = text_clean(corpus, keep_list)\n",
    "    \n",
    "    if remove_stopwords == True:\n",
    "        corpus = stopwords_removal(corpus)\n",
    "    else :\n",
    "        corpus = [[x for x in x.split()] for x in corpus]\n",
    "    \n",
    "    if lemmatization == True:\n",
    "        corpus = lemmatize(corpus)\n",
    "        \n",
    "        \n",
    "    if stemming == True:\n",
    "        corpus = stem(corpus, stem_type)\n",
    "    \n",
    "    corpus = [' '.join(x) for x in corpus]        \n",
    "\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dot_words = ['U.S.', 'Mr.', 'Mrs.', 'D.C.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTRADA:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['We are reading about Natural Language Processing Here',\n",
       " 'Natural Language Processing making computers comprehend language data',\n",
       " 'The field of Natural Language Processing is evolving everyday']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAIDA:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['read natural language process',\n",
       " 'natural language process make computers comprehend language data',\n",
       " 'field natural language process evolve everyday']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing with Lemmatization here\n",
    "preprocessed_corpus = preprocess(\n",
    "    corpus, \n",
    "    keep_list = common_dot_words,\n",
    "    stemming = False, \n",
    "    stem_type = None,\n",
    "    lemmatization = True, \n",
    "    remove_stopwords = True)\n",
    "print(\"ENTRADA:\")\n",
    "display(list(corpus))\n",
    "print(\"\\nSAIDA:\")    \n",
    "preprocessed_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo o vocabulário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comprehend', 'process', 'computers', 'everyday', 'language', 'natural', 'field', 'make', 'data', 'evolve', 'read']\n"
     ]
    }
   ],
   "source": [
    "set_of_words = set()\n",
    "for sentence in preprocessed_corpus:\n",
    "    for word in sentence.split():\n",
    "        set_of_words.add(word)\n",
    "vocab = list(set_of_words)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Otimizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comprehend',\n",
       " 'computers',\n",
       " 'data',\n",
       " 'everyday',\n",
       " 'evolve',\n",
       " 'field',\n",
       " 'language',\n",
       " 'make',\n",
       " 'natural',\n",
       " 'process',\n",
       " 'read'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "set(reduce(lambda a, b: a+b, map(str.split, preprocessed_corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['read', 'natural', 'language', 'process'],\n",
       " ['natural',\n",
       "  'language',\n",
       "  'process',\n",
       "  'make',\n",
       "  'computers',\n",
       "  'comprehend',\n",
       "  'language',\n",
       "  'data'],\n",
       " ['field', 'natural', 'language', 'process', 'evolve', 'everyday']]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['read',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'process',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'process',\n",
       " 'make',\n",
       " 'computers',\n",
       " 'comprehend',\n",
       " 'language',\n",
       " 'data',\n",
       " 'field',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'process',\n",
       " 'evolve',\n",
       " 'everyday']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'comprehend',\n",
       " 'computers',\n",
       " 'data',\n",
       " 'everyday',\n",
       " 'evolve',\n",
       " 'field',\n",
       " 'language',\n",
       " 'make',\n",
       " 'natural',\n",
       " 'process',\n",
       " 'read'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# passo a passo:\n",
    "r = list(map(str.split, preprocessed_corpus))\n",
    "print('1')\n",
    "display(r)\n",
    "r = reduce(lambda a, b: a+b, r)\n",
    "print('2')\n",
    "display(r)\n",
    "r = set(r)\n",
    "print('3')\n",
    "display(r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexando cada palavra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'comprehend': 0, 'process': 1, 'computers': 2, 'everyday': 3, 'language': 4, 'natural': 5, 'field': 6, 'make': 7, 'data': 8, 'evolve': 9, 'read': 10}\n"
     ]
    }
   ],
   "source": [
    "position = {}\n",
    "for i, token in enumerate(vocab):\n",
    "    position[token] = i\n",
    "print(position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Otimizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comprehend': 0,\n",
       " 'process': 1,\n",
       " 'computers': 2,\n",
       " 'everyday': 3,\n",
       " 'language': 4,\n",
       " 'natural': 5,\n",
       " 'field': 6,\n",
       " 'make': 7,\n",
       " 'data': 8,\n",
       " 'evolve': 9,\n",
       " 'read': 10}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(vocab, range(len(vocab))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação da matriz Bag of Words\n",
    "\n",
    "O formato da matriz é (num de sentenças x tamanho do vocabulário),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessed_corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19776/1484612145.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessed_corpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbow_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessed_corpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbow_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocessed_corpus' is not defined"
     ]
    }
   ],
   "source": [
    "display(preprocessed_corpus)\n",
    "display(vocab)\n",
    "bow_matrix = np.zeros((len(preprocessed_corpus), len(vocab)))\n",
    "bow_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1.],\n",
       "       [1., 1., 1., 0., 2., 1., 0., 1., 1., 0., 0.],\n",
       "       [0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, preprocessed_sentence in enumerate(preprocessed_corpus):\n",
    "    for token in preprocessed_sentence.split():   \n",
    "        bow_matrix[i][position[token]] = bow_matrix[i][position[token]] + 1\n",
    "bow_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frase 1</th>\n",
       "      <th>frase 2</th>\n",
       "      <th>frase 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comprehend</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>process</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computers</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>everyday</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natural</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>field</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evolve</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>read</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            frase 1  frase 2  frase 3\n",
       "comprehend      0.0      1.0      0.0\n",
       "process         1.0      1.0      1.0\n",
       "computers       0.0      1.0      0.0\n",
       "everyday        0.0      0.0      1.0\n",
       "language        1.0      2.0      1.0\n",
       "natural         1.0      1.0      1.0\n",
       "field           0.0      0.0      1.0\n",
       "make            0.0      1.0      0.0\n",
       "data            0.0      1.0      0.0\n",
       "evolve          0.0      0.0      1.0\n",
       "read            1.0      0.0      0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# renderizando em um DataFrame para melhor visualização\n",
    "pd.DataFrame(bow_matrix, columns=vocab, index=['frase 1', 'frase 2', 'frase 3']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferência\n",
    "\n",
    "Tomando como exemplo a palavra *language* na *bow_matrix*, os valores são 1, 2 e 1 respectivamente.\n",
    "\n",
    "*language* ocorre **uma, duas e uma vez** nas sentenças 1, 2 e 3 respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício\n",
    "\n",
    "Experimente incluir bigramas e trigramas no modelo BoW."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerações\n",
    "\n",
    "**- Pró**\n",
    "  - Simplicidade\n",
    "  - Computacionalmente rápido*\n",
    "\n",
    "- **Contra**\n",
    "  1. Não leva em consideração a **semântica** ou **significados** associados a um token ou frases em um documento.\n",
    "  2. Não captura *features* obervando a vizinhança de uma token <sub>(que poderia sugerir o contexto em que uma palavra)</sub>.\n",
    "  3. Igoram tokens ou frases que ocorrem muito raramente <sub>(que podem ser muito importantes na representação dos documentos)</sub>.\n",
    "  4. Pode ficar **extremamente grande em termos de vocabulário**, dependendo do tamanho do corpus, o que pode causar uma deterioração no desempenho computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer para o modelo Bag of Words\n",
    "\n",
    "**Documentação**: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\luizf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\luizf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo um corpus de sentenças"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"We are reading about Natural Language Processing Here\",\n",
    "            \"Natural Language Processing making computers comprehend language data\",\n",
    "            \"The field of Natural Language Processing is evolving everyday\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    We are reading about Natural Language Processi...\n",
       "1    Natural Language Processing making computers c...\n",
       "2    The field of Natural Language Processing is ev...\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.Series(sentences)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline de pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTRADA:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['We are reading about Natural Language Processing Here',\n",
       " 'Natural Language Processing making computers comprehend language data',\n",
       " 'The field of Natural Language Processing is evolving everyday']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAIDA:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['read natural language process',\n",
       " 'natural language process make computers comprehend language data',\n",
       " 'field natural language process evolve everyday']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pré-processando com lematização\n",
    "preprocessed_corpus = preprocess(corpus, keep_list = [], stemming = False, stem_type = None,\n",
    "                                lemmatization = True, remove_stopwords = True)\n",
    "\n",
    "\n",
    "print(\"ENTRADA:\")\n",
    "display(list(corpus))\n",
    "print(\"\\nSAIDA:\")    \n",
    "preprocessed_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit e Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'read': 10,\n",
       " 'natural': 8,\n",
       " 'language': 6,\n",
       " 'process': 9,\n",
       " 'make': 7,\n",
       " 'computers': 1,\n",
       " 'comprehend': 0,\n",
       " 'data': 2,\n",
       " 'field': 5,\n",
       " 'evolve': 4,\n",
       " 'everyday': 3}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# treina o preparador criando o vocabulário\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(preprocessed_corpus)\n",
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x11 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 17 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_matrix = vectorizer.transform(preprocessed_corpus)\n",
    "bow_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fit_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_bow_matrix(bow_matrix, vectorizer):\n",
    "    df = pd.DataFrame(bow_matrix.toarray(), columns=vectorizer.get_feature_names()).T\n",
    "    df.columns = [f'qtd{c}' for c in df.columns]\n",
    "    print('BoW Matrix Shape: ', df.shape)\n",
    "    df['Total'] = df.astype(bool).sum(axis=1)\n",
    "    df.index.name = 'n-grams'\n",
    "    return df.sort_values(['Total', 'n-grams'], ascending=False).reset_index()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x11 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 17 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "bow_matrix = vectorizer.fit_transform(preprocessed_corpus)\n",
    "bow_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observando quais features foram obtidas e a matriz correspondente do Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Matrix Shape:  (11, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n-grams</th>\n",
       "      <th>qtd0</th>\n",
       "      <th>qtd1</th>\n",
       "      <th>qtd2</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>process</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>natural</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>language</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>read</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>make</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>field</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>evolve</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>everyday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>computers</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>comprehend</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n-grams  qtd0  qtd1  qtd2  Total\n",
       "0      process     1     1     1      3\n",
       "1      natural     1     1     1      3\n",
       "2     language     1     2     1      3\n",
       "3         read     1     0     0      1\n",
       "4         make     0     1     0      1\n",
       "5        field     0     0     1      1\n",
       "6       evolve     0     0     1      1\n",
       "7     everyday     0     0     1      1\n",
       "8         data     0     1     0      1\n",
       "9    computers     0     1     0      1\n",
       "10  comprehend     0     1     0      1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_bow_matrix(bow_matrix, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>A matriz é a mesma obtida depois de todo o trabalho duro do notebook anterior.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos ver como bigramas e trigramas podem ser incluídos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_ngram_range = CountVectorizer(analyzer='word', ngram_range=(1,3))\n",
    "bow_matrix_ngram = vectorizer_ngram_range.fit_transform(preprocessed_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Matrix Shape:  (32, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n-grams</th>\n",
       "      <th>qtd0</th>\n",
       "      <th>qtd1</th>\n",
       "      <th>qtd2</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>process</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>natural language process</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>natural language</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>natural</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>language process</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>language</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>read natural language</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>read natural</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>read</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>process make computers</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>process make</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>process evolve everyday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>process evolve</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>make computers comprehend</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>make computers</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>make</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>language process make</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>language process evolve</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>language data</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>field natural language</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>field natural</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>field</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>evolve everyday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>evolve</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>everyday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>data</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>computers comprehend language</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>computers comprehend</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>computers</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>comprehend language data</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>comprehend language</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>comprehend</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          n-grams  qtd0  qtd1  qtd2  Total\n",
       "0                         process     1     1     1      3\n",
       "1        natural language process     1     1     1      3\n",
       "2                natural language     1     1     1      3\n",
       "3                         natural     1     1     1      3\n",
       "4                language process     1     1     1      3\n",
       "5                        language     1     2     1      3\n",
       "6           read natural language     1     0     0      1\n",
       "7                    read natural     1     0     0      1\n",
       "8                            read     1     0     0      1\n",
       "9          process make computers     0     1     0      1\n",
       "10                   process make     0     1     0      1\n",
       "11        process evolve everyday     0     0     1      1\n",
       "12                 process evolve     0     0     1      1\n",
       "13      make computers comprehend     0     1     0      1\n",
       "14                 make computers     0     1     0      1\n",
       "15                           make     0     1     0      1\n",
       "16          language process make     0     1     0      1\n",
       "17        language process evolve     0     0     1      1\n",
       "18                  language data     0     1     0      1\n",
       "19         field natural language     0     0     1      1\n",
       "20                  field natural     0     0     1      1\n",
       "21                          field     0     0     1      1\n",
       "22                evolve everyday     0     0     1      1\n",
       "23                         evolve     0     0     1      1\n",
       "24                       everyday     0     0     1      1\n",
       "25                           data     0     1     0      1\n",
       "26  computers comprehend language     0     1     0      1\n",
       "27           computers comprehend     0     1     0      1\n",
       "28                      computers     0     1     0      1\n",
       "29       comprehend language data     0     1     0      1\n",
       "30            comprehend language     0     1     0      1\n",
       "31                     comprehend     0     1     0      1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_bow_matrix(bow_matrix_ngram, vectorizer_ngram_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inferência\n",
    "\n",
    "A frase *natural language process*, no índice 23, aparece ao menos uma vez em cada sentença.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parâmetro Max Features\n",
    "\n",
    "Uma grande dimensionalidade do vocabulário não converte em um bom modelo, podendo gerar *overfitting*.\n",
    "\n",
    "Para isso é necessário dispor de recursos para limitá-lo.\n",
    "\n",
    "O `CountVectorizer` possui um parâmetro chamado `max_features`, que limita o vocabulário para ser menor ou igual ao seu valor, ordenado pela frequência entre as sentenças."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Matrix Shape:  (8, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n-grams</th>\n",
       "      <th>qtd0</th>\n",
       "      <th>qtd1</th>\n",
       "      <th>qtd2</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>process</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>natural language process</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>natural language</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>natural</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>language process</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>language</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>read</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>process make computers</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    n-grams  qtd0  qtd1  qtd2  Total\n",
       "0                   process     1     1     1      3\n",
       "1  natural language process     1     1     1      3\n",
       "2          natural language     1     1     1      3\n",
       "3                   natural     1     1     1      3\n",
       "4          language process     1     1     1      3\n",
       "5                  language     1     2     1      3\n",
       "6                      read     1     0     0      1\n",
       "7    process make computers     0     1     0      1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CountVectorizer(analyzer='word', ngram_range=(1,3), max_features = 6).fit(preprocessed_corpus).vocabulary_\n",
    "vectorizer_max_features = CountVectorizer(analyzer='word', ngram_range=(1,3), max_features = 8)\n",
    "bow_matrix_max_features = vectorizer_max_features.fit_transform(preprocessed_corpus)\n",
    "show_bow_matrix(bow_matrix_max_features, vectorizer_max_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inferência\n",
    "\n",
    "Limita o vocabulário aos 6 n-gramas mais frequentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limites usando os parâmetros `max_df` e `min_df`\n",
    "\n",
    "Num texto é possível que haja **palavras ou frases que aparecem muitas vezes** e **não possuem qualquer padrão**.\n",
    "\n",
    "Há também palavras que apacerem raramente e apenas poluem o vocabulário.\n",
    "\n",
    "Uma maneira de resolver esses problemas é **determinando uma quantidade máxima e/ou mínima de vezes em que uma palavra ou frase pode aparecer nas sentenças para ser considerado parte do vocabulário**.\n",
    "\n",
    "O preparador `CountVectorizer` posssi os parâmetros:\n",
    "\n",
    "- `max_df`: determina a quantidade máxima\n",
    "- `min_df` determina a quantidade mínima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_maxmin_df = CountVectorizer(analyzer='word', ngram_range=(1,3), max_df=3, min_df=2)\n",
    "bow_matrix_maxmin_df = vectorizer_maxmin_df.fit_transform(preprocessed_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Matrix Shape:  (6, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n-grams</th>\n",
       "      <th>qtd0</th>\n",
       "      <th>qtd1</th>\n",
       "      <th>qtd2</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>process</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>natural language process</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>natural language</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>natural</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>language process</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>language</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    n-grams  qtd0  qtd1  qtd2  Total\n",
       "0                   process     1     1     1      3\n",
       "1  natural language process     1     1     1      3\n",
       "2          natural language     1     1     1      3\n",
       "3                   natural     1     1     1      3\n",
       "4          language process     1     1     1      3\n",
       "5                  language     1     2     1      3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_bow_matrix(bow_matrix_maxmin_df, vectorizer_maxmin_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferência\n",
    "\n",
    "Somente as n-gramas presentes de 1 a 3 sentenças estão presentes no vocabulário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrando o preparador `CountVectorizer` sem nenhuma restrição, a fim de comparar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Matrix Shape:  (32, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n-grams</th>\n",
       "      <th>qtd0</th>\n",
       "      <th>qtd1</th>\n",
       "      <th>qtd2</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>process</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>natural language process</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>natural language</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>natural</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>language process</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>language</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>read natural language</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>read natural</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>read</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>process make computers</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>process make</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>process evolve everyday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>process evolve</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>make computers comprehend</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>make computers</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>make</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>language process make</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>language process evolve</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>language data</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>field natural language</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>field natural</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>field</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>evolve everyday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>evolve</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>everyday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>data</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>computers comprehend language</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>computers comprehend</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>computers</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>comprehend language data</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>comprehend language</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>comprehend</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          n-grams  qtd0  qtd1  qtd2  Total\n",
       "0                         process     1     1     1      3\n",
       "1        natural language process     1     1     1      3\n",
       "2                natural language     1     1     1      3\n",
       "3                         natural     1     1     1      3\n",
       "4                language process     1     1     1      3\n",
       "5                        language     1     2     1      3\n",
       "6           read natural language     1     0     0      1\n",
       "7                    read natural     1     0     0      1\n",
       "8                            read     1     0     0      1\n",
       "9          process make computers     0     1     0      1\n",
       "10                   process make     0     1     0      1\n",
       "11        process evolve everyday     0     0     1      1\n",
       "12                 process evolve     0     0     1      1\n",
       "13      make computers comprehend     0     1     0      1\n",
       "14                 make computers     0     1     0      1\n",
       "15                           make     0     1     0      1\n",
       "16          language process make     0     1     0      1\n",
       "17        language process evolve     0     0     1      1\n",
       "18                  language data     0     1     0      1\n",
       "19         field natural language     0     0     1      1\n",
       "20                  field natural     0     0     1      1\n",
       "21                          field     0     0     1      1\n",
       "22                evolve everyday     0     0     1      1\n",
       "23                         evolve     0     0     1      1\n",
       "24                       everyday     0     0     1      1\n",
       "25                           data     0     1     0      1\n",
       "26  computers comprehend language     0     1     0      1\n",
       "27           computers comprehend     0     1     0      1\n",
       "28                      computers     0     1     0      1\n",
       "29       comprehend language data     0     1     0      1\n",
       "30            comprehend language     0     1     0      1\n",
       "31                     comprehend     0     1     0      1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "bow_matrix = vectorizer.fit_transform(preprocessed_corpus)\n",
    "show_bow_matrix(bow_matrix, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Texto para testar o `max_df` e o `min_df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n-grams</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seis</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cinco</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quatro</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tres</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dois</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>um</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n-grams  0  1  2  3  4  5  Total\n",
       "3    seis  6  1  4  1  2  1      6\n",
       "0   cinco  5  2  3  2  1  0      5\n",
       "2  quatro  4  3  2  3  0  0      4\n",
       "4    tres  3  4  1  0  0  0      3\n",
       "1    dois  2  5  0  0  0  0      2\n",
       "5      um  1  0  0  0  0  0      1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [\n",
    "\"Um dois dois tres tres tres quatro quatro quatro quatro cinco cinco cinco cinco cinco seis seis seis seis seis seis\",\n",
    "\"dois dois dois dois dois tres tres tres tres quatro quatro quatro cinco cinco seis\",\n",
    "\"tres quatro quatro cinco cinco cinco seis seis seis seis\",\n",
    "\"quatro quatro quatro cinco cinco seis\",\n",
    "\"cinco seis seis\",\n",
    "\"seis\" \n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "bow_matrix = vectorizer.fit_transform(text)\n",
    "df = pd.DataFrame(bow_matrix.toarray(), columns=vectorizer.get_feature_names()).T.reset_index().rename(columns={'index': 'n-grams'})\n",
    "df['Total'] = df.iloc[:, 1:].astype(bool).sum(axis=1)\n",
    "df.sort_values(['Total', 'n-grams'], ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n-grams</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cinco</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quatro</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tres</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dois</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n-grams  0  1  2  3  4  5  Total\n",
       "0   cinco  5  2  3  2  1  0      5\n",
       "2  quatro  4  3  2  3  0  0      4\n",
       "3    tres  3  4  1  0  0  0      3\n",
       "1    dois  2  5  0  0  0  0      2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(max_df=5, min_df=2)\n",
    "bow_matrix = vectorizer.fit_transform(text)\n",
    "df = pd.DataFrame(bow_matrix.toarray(), columns=vectorizer.get_feature_names()).T.reset_index().rename(columns={'index': 'n-grams'})\n",
    "df['Total'] = df.iloc[:, 1:].astype(bool).sum(axis=1)\n",
    "df.sort_values(['Total', 'n-grams'], ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerações\n",
    "\n",
    "\n",
    "**- Pró**\n",
    "  - Simplicidade\n",
    "  - Computacionalmente rápido*\n",
    "\n",
    "- **Contra**\n",
    "  1. Não leva em consideração a **semântica** ou **significados** associados a um token ou frases em um documento.\n",
    "  2. Não captura *features* obervando a vizinhança de uma token <sub>(que poderia sugerir o contexto em que uma palavra)</sub>.\n",
    "  3. Igoram tokens ou frases que ocorrem muito raramente <sub>(que podem ser muito importantes na representação dos documentos)</sub>.\n",
    "  4. Pode ficar **extremamente grande em termos de vocabulário**, dependendo do tamanho do corpus, o que pode causar uma deterioração no desempenho computacional.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "Vetorizador baseado em frequência de documento inverso de frequência de termo\n",
    "\n",
    "**Documentação**: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "**Código Fonte**: https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/feature_extraction/text.py\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2021/11/how-sklearns-tfidfvectorizer-calculates-tf-idf-values/\n",
    "\n",
    "https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\luizf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\luizf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Premissa:** \n",
    "\n",
    "No BoW as palavras que ocorrem raramente são removidas ou seus pesos são muito baixos em relação à palavras que ocorrem muito frequentemente.\n",
    "\n",
    "Porém, essas palavras podem carregar uma grande quantidade de informações sobre um documento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intuição**\n",
    "\n",
    "Para resolver o problema das palavras raras importantes, o TD-IDF propõe 2 termos:\n",
    "\n",
    "- **TF**\n",
    "  \n",
    "    > Similar ao `CountVectorizer`, porém com a **normalização da frequência** ao dividir a quantidade encontrada pela quantidade de palavras do documento\n",
    "\n",
    "\n",
    "$$\n",
    "TF(w) = \\frac{\\space Número \\space de \\space vezes \\space que \\space a \\space palavra \\space ocorre \\space no \\space documento/frase}\n",
    "    {Número \\space total \\space de \\space palavras \\space do \\space documento/frase}\n",
    "$$\n",
    "\n",
    "  Palavras que aparecem bastante em documentos longos são balanceadas com as que aparecem menos porque o documento é menor.\n",
    "\n",
    "\n",
    "- IDF\n",
    "  \n",
    "    > Mede a importância do termo no documento.\n",
    "\n",
    "  - Fórmula livro:\n",
    "\n",
    "$$\n",
    "IDF(w) = log \\frac{Quantidade \\space de \\space documentos/frases}\n",
    "    {\\text{Número \\space de \\space documentos \\space que \\space contém \\space a \\space palavra \\space w}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfIdfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Sciki-Learn faz uma implementação do IDF um pouco diferente na sua classe `TfIdfVectorizer`:\n",
    "\n",
    "Se o parâmetro `smooth_idf=True`:\n",
    "\n",
    "$\n",
    "IDF(w) =  ln \\left( \n",
    "    \\frac{1 + \\text{Quantidade de documentos/frases}}\n",
    "         {1 + \\text{Número \\space de \\space documentos \\space que \\space contém \\space a \\space palavra \\space w}}\n",
    "    \\right) + 1\n",
    "$\n",
    "\n",
    "Se o parâmetro `smooth_idf=False`:\n",
    "\n",
    "$\n",
    "IDF(w) =  ln \\left( \n",
    "    \\frac{\\text{Quantidade de documentos/frases}}\n",
    "         {\\text{Número \\space de \\space documentos \\space que \\space contém \\space a \\space palavra \\space w}}\n",
    "    \\right) + 1\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, o  `TfIdfVectorizer` realiza uma normalização:\n",
    "\n",
    "- L2: se parâmetro `norm = 'l2'`  ou default:\n",
    "\n",
    "$\n",
    "v_{norm} = \\frac{v}{||v||_2} = \\frac{v}{\\sqrt{v{_1}^2 +\n",
    "v{_2}^2 + \\dots + v{_n}^2}}\n",
    "$\n",
    "\n",
    "- L1: se parâmetro `norm = 'l1'`:\n",
    "\n",
    "$\n",
    "v_{norm} = \\frac{v}{||v||_1} = \\frac{v}{|v{_1}| +\n",
    "|v{_2}| + \\dots + |v{_n}|}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mostrando a evolução do IDF em relação ao percentual de documentos com uma determinada palavra**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qtd_docs_com_palavra</th>\n",
       "      <th>%</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qtd_docs_com_palavra      %   idf\n",
       "0                     1    6.0  3.14\n",
       "1                     4   25.0  2.22\n",
       "2                     8   50.0  1.64\n",
       "3                    12   75.0  1.27\n",
       "4                    16  100.0  1.00"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_docs = 16\n",
    "\n",
    "df = pd.Series([1, 4, 8, 12, 16], name='qtd_docs_com_palavra').to_frame()\n",
    "df['%'] = ((df['qtd_docs_com_palavra'] / total_docs) * 100).round(0)\n",
    "df['idf'] = np.log((1 + total_docs) / (1 + df['qtd_docs_com_palavra'])) + 1\n",
    "df['idf'] = df['idf'].round(2)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando o TfidfVectorizer Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tf_idf_matrix = vectorizer.fit_transform(preprocessed_corpus)\n",
    "vectorizer.smooth_idf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tlidf_matrix(matrix, vectorizer):\n",
    "    df = pd.DataFrame(matrix.toarray(), columns=vectorizer.get_feature_names()).T \n",
    "    df.columns = [f'TF-IDF{c}' for c in range(len(df.columns))]\n",
    "    sorted_indexes = df.sum(axis=1).sort_values(ascending=False).index\n",
    "    df['idf'] = vectorizer.idf_\n",
    "    \n",
    "    df.index.name = 'n-grams'\n",
    "    print(\"\\nThe shape of the TF-IDF matrix is: \", tf_idf_matrix.shape)     \n",
    "    \n",
    "    return df.loc[sorted_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As colunas 0, 1 e 2 normalizadas pela norma **l2** e o IDF calculado de cada palavra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The shape of the TF-IDF matrix is:  (3, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF-IDF0</th>\n",
       "      <th>TF-IDF1</th>\n",
       "      <th>TF-IDF2</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <td>0.412859</td>\n",
       "      <td>0.478543</td>\n",
       "      <td>0.293607</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natural</th>\n",
       "      <td>0.412859</td>\n",
       "      <td>0.239271</td>\n",
       "      <td>0.293607</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>process</th>\n",
       "      <td>0.412859</td>\n",
       "      <td>0.239271</td>\n",
       "      <td>0.293607</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>read</th>\n",
       "      <td>0.699030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>everyday</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497120</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evolve</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497120</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>field</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497120</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comprehend</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computers</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TF-IDF0   TF-IDF1   TF-IDF2       idf\n",
       "language    0.412859  0.478543  0.293607  1.000000\n",
       "natural     0.412859  0.239271  0.293607  1.000000\n",
       "process     0.412859  0.239271  0.293607  1.000000\n",
       "read        0.699030  0.000000  0.000000  1.693147\n",
       "everyday    0.000000  0.000000  0.497120  1.693147\n",
       "evolve      0.000000  0.000000  0.497120  1.693147\n",
       "field       0.000000  0.000000  0.497120  1.693147\n",
       "comprehend  0.000000  0.405122  0.000000  1.693147\n",
       "computers   0.000000  0.405122  0.000000  1.693147\n",
       "data        0.000000  0.405122  0.000000  1.693147\n",
       "make        0.000000  0.405122  0.000000  1.693147"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl_idf_default = show_tlidf_matrix(tf_idf_matrix, vectorizer)\n",
    "tl_idf_default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementação manual do TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Matrix Shape:  (11, 3)\n",
      "Num. palavras em cada documento: [4, 8, 6]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n-grams</th>\n",
       "      <th>qtd0</th>\n",
       "      <th>qtd1</th>\n",
       "      <th>qtd2</th>\n",
       "      <th>Total</th>\n",
       "      <th>TF0</th>\n",
       "      <th>TF1</th>\n",
       "      <th>TF2</th>\n",
       "      <th>IDF</th>\n",
       "      <th>TF-IDF0</th>\n",
       "      <th>TF-IDF1</th>\n",
       "      <th>TF-IDF2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>process</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>natural</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>language</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>read</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>0.423287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>make</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211643</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>field</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>evolve</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>everyday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211643</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>computers</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211643</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>comprehend</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211643</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n-grams  qtd0  qtd1  qtd2  Total   TF0    TF1       TF2       IDF  \\\n",
       "0      process     1     1     1      3  0.25  0.125  0.166667  1.000000   \n",
       "1      natural     1     1     1      3  0.25  0.125  0.166667  1.000000   \n",
       "2     language     1     2     1      3  0.25  0.250  0.166667  1.000000   \n",
       "3         read     1     0     0      1  0.25  0.000  0.000000  1.693147   \n",
       "4         make     0     1     0      1  0.00  0.125  0.000000  1.693147   \n",
       "5        field     0     0     1      1  0.00  0.000  0.166667  1.693147   \n",
       "6       evolve     0     0     1      1  0.00  0.000  0.166667  1.693147   \n",
       "7     everyday     0     0     1      1  0.00  0.000  0.166667  1.693147   \n",
       "8         data     0     1     0      1  0.00  0.125  0.000000  1.693147   \n",
       "9    computers     0     1     0      1  0.00  0.125  0.000000  1.693147   \n",
       "10  comprehend     0     1     0      1  0.00  0.125  0.000000  1.693147   \n",
       "\n",
       "     TF-IDF0   TF-IDF1   TF-IDF2  \n",
       "0   0.250000  0.125000  0.166667  \n",
       "1   0.250000  0.125000  0.166667  \n",
       "2   0.250000  0.250000  0.166667  \n",
       "3   0.423287  0.000000  0.000000  \n",
       "4   0.000000  0.211643  0.000000  \n",
       "5   0.000000  0.000000  0.282191  \n",
       "6   0.000000  0.000000  0.282191  \n",
       "7   0.000000  0.000000  0.282191  \n",
       "8   0.000000  0.211643  0.000000  \n",
       "9   0.000000  0.211643  0.000000  \n",
       "10  0.000000  0.211643  0.000000  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "bow_matrix = vectorizer.fit_transform(preprocessed_corpus)\n",
    "_df = show_bow_matrix(bow_matrix, vectorizer)\n",
    "doc_counts = list(map(lambda x: x.count(' ') + 1, preprocessed_corpus))\n",
    "print('Num. palavras em cada documento:', doc_counts)\n",
    "\n",
    "# TF\n",
    "t =  _df.iloc[:, 1:-1]\n",
    "t.columns = [f'TF{c}' for c in range(len(t.columns))]\n",
    "t = t.div(doc_counts)\n",
    "_df = pd.concat([_df, t], axis=1)\n",
    "\n",
    "# IDF\n",
    "t = np.log(((1 + len(preprocessed_corpus)) / (1 + _df['Total'])).rename('IDF') ) + 1\n",
    "_df = pd.concat([_df, t ], axis=1)\n",
    "\n",
    "# # TL-IDF\n",
    "t = _df.filter(regex='^TF\\d$').mul(_df['IDF'], axis=0)\n",
    "t.div(t.pow(2).sum().pow(.5))\n",
    "t.columns = [f'TF-IDF{c}' for c in range(len(preprocessed_corpus))]\n",
    "_df = pd.concat([_df, t], axis=1) \n",
    "_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\tiny\n",
    "TF(w) = \\frac{\\space Número \\space de \\space vezes \\space que \\space a \\space palavra \\space ocorre \\space no \\space documento/frase}\n",
    "    {Número \\space total \\space de \\space palavras \\space do \\space documento/frase}\n",
    "$\n",
    "\n",
    "$\n",
    "\\tiny\n",
    "IDF(w) =  ln \\left( \n",
    "    \\frac{1 + \\text{Quantidade de documentos/frases}}\n",
    "         {1 + \\text{Número \\space de \\space documentos \\space que \\space contém \\space a \\space palavra \\space w}}\n",
    "    \\right) + 1\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mudando para norma l1 (l2 é padrão)\n",
    "\n",
    "Cada linha de saída terá uma norma unitária, que pode ser:\n",
    "\n",
    "**l2**: A soma dos quadrados dos elementos vetoriais é 1.\n",
    "\n",
    "**l1**: A soma dos valores absolutos dos elementos do vetor é 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Diferenças entre as normas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valores</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>l3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.050965</td>\n",
       "      <td>0.069145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.101929</td>\n",
       "      <td>0.138289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0.152894</td>\n",
       "      <td>0.207434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.072727</td>\n",
       "      <td>0.203859</td>\n",
       "      <td>0.276578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.254824</td>\n",
       "      <td>0.345723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>0.305788</td>\n",
       "      <td>0.414868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.356753</td>\n",
       "      <td>0.484012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.407718</td>\n",
       "      <td>0.553157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.163636</td>\n",
       "      <td>0.458682</td>\n",
       "      <td>0.622301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.509647</td>\n",
       "      <td>0.691446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   valores        l1        l2        l3\n",
       "0        1  0.018182  0.050965  0.069145\n",
       "1        2  0.036364  0.101929  0.138289\n",
       "2        3  0.054545  0.152894  0.207434\n",
       "3        4  0.072727  0.203859  0.276578\n",
       "4        5  0.090909  0.254824  0.345723\n",
       "5        6  0.109091  0.305788  0.414868\n",
       "6        7  0.127273  0.356753  0.484012\n",
       "7        8  0.145455  0.407718  0.553157\n",
       "8        9  0.163636  0.458682  0.622301\n",
       "9       10  0.181818  0.509647  0.691446"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAATPklEQVR4nO3df5BdZ13H8fenaVIKpYLNIpo0TdUoRqcF3BQRxCLgtOIQtVVaf2tnYtGCOipUnVHHHzOKjqJOtRPbij8wHYcCVq1WBx1xVCTb0hYDVDMFzLbFxlraRkObkK9/3Btyd3uT0LJnz9l93q+Znd1zzrP3PrmT3c+ec773+aaqkCS165S+JyBJ6pdBIEmNMwgkqXEGgSQ1ziCQpMad2vcEnqz169fX5s2b+56GJK0ot912239X1cy0YysuCDZv3szc3Fzf05CkFSXJx453zEtDktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkaSXYvx927x59XmIGgSQN3a5dcM458KpXjT7v2rWkD28QSNKQ7d8PV1wBBw/Cww+PPl9xxZKeGRgEkjRkH/0orFu3cN/ataP9S6TTIEhyUZK7k+xNcvWU4xcmeTjJHeOPn+lyPpK04mzeDI8/vnDfoUOj/UuksyBIsga4BrgY2ApcnmTrlKH/WFXPH3/8fFfzkaQVaWYGrr8eTj8dzjxz9Pn660f7l0iXaw1dAOytqnsAktwIbAc+2OFzStLqc/nl8MpXji4Hbd68pCEA3V4a2gDsm9ieH+9b7MVJ7kzyV0m+fNoDJdmRZC7J3P4OSqckafBmZmDbtiUPAeg2CDJlXy3avh04p6rOB34beNe0B6qqnVU1W1WzMx28CJLUsi6DYB44e2J7I3Df5ICqeqSqDoy/vgVYm2R9h3OSJC3SZRDsBrYkOTfJOuAy4ObJAUmemyTjry8Yz+fBDuckSVqks5vFVXU4yVXArcAa4Iaq2pPkyvHxa4FLgdclOQwcBC6rqsWXjyRJHcpK+707OztbdiiTpCcnyW1VNTvtmO8slqTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkE+mwafxQGASSdDwdN40fCoNAkqZZhqbxQ2EQSNI0y9A0figMAkmaZhmaxg+FQSBJ0yxD0/ih6LJ5vSStbB03jR8Kg0CSTmRmZtUGwFFeGpKkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCScPUQK/goTAIJA1PI72Ch8IgkDQsDfUKHopOgyDJRUnuTrI3ydUnGLctyaeSXNrlfCStAA31Ch6KzoIgyRrgGuBiYCtweZKtxxn3K8CtXc1F0grSUK/goejyjOACYG9V3VNVjwM3AtunjHs9cBPwQIdzkbRSNNQreCi6bFW5Adg3sT0PvGhyQJINwDcDXwdsO94DJdkB7ADYtGnTkk9U0sA00it4KLoMgkzZV4u23wK8qao+lUwbPv6mqp3AToDZ2dnFjyFpNWqgV/BQdBkE88DZE9sbgfsWjZkFbhyHwHrgG5Icrqp3dTgvSdKELoNgN7AlybnAvcBlwLdPDqiqc49+neStwF8YApK0vDoLgqo6nOQqRtVAa4AbqmpPkivHx6/t6rklSZ+5Ls8IqKpbgFsW7ZsaAFX1vV3ORZI0ne8slqTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEkhayaXxzDAJJx9g0vkkGgaQRm8Y3yyCQNGLT+GYZBJJGbBrfLINA0ohN45vVaT8CSSuMTeObZBBIWsim8c3x0pAkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSENiv2D1wCCQhsJ+wepJp0GQ5KIkdyfZm+TqKce3J7kryR1J5pK8tMv5SINlv2D1qLMgSLIGuAa4GNgKXJ5k66Jh7wbOr6rnA98PXNfVfKRBs1+wetTlGcEFwN6quqeqHgduBLZPDqiqA1VV481nAIXUIvsFq0ddBsEGYN/E9vx43wJJvjnJh4G/ZHRWILXHfsHqUZetKjNl3xP+4q+qdwLvTPIy4BeAVz7hgZIdwA6ATZs2LfE0pYGwX7B60uUZwTxw9sT2RuC+4w2uqvcAX5Rk/ZRjO6tqtqpmZ/zh0Go2MwPbthkCWlZdBsFuYEuSc5OsAy4Dbp4ckOSLk2T89QuBdcCDHc5JkrRIZ5eGqupwkquAW4E1wA1VtSfJlePj1wKXAN+d5BBwEHjtxM1jSdIyyEr7vTs7O1tzc3N9T0OSVpQkt1XV7LRjvrNYkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1LiTBkGSM5N80ZT953UzJUnScjphECT5NuDDwE1J9iTZNnH4rV1OTJK0PE52RvBTwFeOO4h9H/BHSb5lfGzaMtPSymTTeDXsZEGwpqruB6iq9wEvB346yRuwm5hWC5vGq3EnC4JHJ+8PjEPhQkYtJ7+8w3lJy8Om8dJJg+B1i8dU1aPARdhWUquBTeOlE/cjqKo7j7P/EPC2TmYkLSebxksnrRp6NMkjUz4eTfLIck1S6oxN46WTnhE8c7kmIvXGpvFqXGetKqUVZWbGAFCzXGJCkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCNQvewVLvTMI1B97BUuD0GkQJLkoyd1J9ia5esrx70hy1/jjn5Oc3+V8NCD2CpYGo7MgSLIGuAa4GNgKXJ5k66JhHwG+tqrOA34B2NnVfDQw9gqWBqPLM4ILgL1VdU9VPQ7cCGyfHFBV/1xVD4033wts7HA+GhJ7BUuD0WUQbAD2TWzPj/cdzxXAX007kGRHkrkkc/u9dLA62CtYGowuW1Vmyr6aOjB5OaMgeOm041W1k/Flo9nZ2amPoRXIXsHSIHQZBPPA2RPbG4H7Fg9Kch5wHXBxVT3Y4Xw0RPYKlnrX5aWh3cCWJOcmWQdcBtw8OSDJJuAdwHdV1b93OBdJ0nF0dkZQVYeTXAXcCqwBbqiqPUmuHB+/FvgZ4Czgd5IAHK6q2a7mJEkr1YMHHmP+oYNsfPbpnHXGaUv62KlaWZfcZ2dna25uru9pSNKy+bM77uVNN93F2lNO4dCRI7z5kvN4zfNPVHvzREluO94f2r6zWJIG7MEDj/Gmm+7ik4eO8Ohjh/nkoSO88aa7ePDAY0v2HAaBJA3Y/EMHWXvKwl/Va085hfmHDi7ZcxgEkjRgG599OoeOHFmw79CRI2x89ulL9hwGgSQN2FlnnMabLzmPp609hWeedipPW3sKb77kvCW9Ydzl+wgkSUvgNc/fwEu+eH1nVUMGgSSdQJdlm0/GWWec1tnzGwSSdBxLUba5EniPQJKmWI6yzaEwCCRpiuUo2xwKg0CSpliOss2hMAhaZdN46YSWo2xzKLxZ3KJdu0b9gdetG3UJu/76UW8ASQt0XbY5FC4615r9++Gcc0bN4o86/XT42MfsCyCtYi46p2NsGq8V4sEDj3Hnvk+syiqdofHSUGtsGq8VoJX6/aHwjKA1No3XwLVUvz8UnhG0yKbxGrCj9fuf5Fjp5tH6/dV6s7ZvBkGrbBqvgWqpfn8ovDQkaVBaqt8fCs8IJA1OK/X7Q2EQSFqghWWXtZBBIOnTLNtsk/cIJAGWbbbMIJAEtLXsshYyCCQBlm22zCCQBFi22TJvFkv6NMs222QQSAMyhNJNyzbbYxBIA2HppvriPQJpACzdVJ8MguVmr2BNYemm+tRpECS5KMndSfYmuXrK8ecl+ZckjyX58S7nMgi7do3aRL7qVaPPu3b1PSMNhKWb6lNnQZBkDXANcDGwFbg8ydZFw/4HeAPwa13NYzD27x81jD94EB5+ePT5iis8MxBg6ab61eXN4guAvVV1D0CSG4HtwAePDqiqB4AHkry6w3kMw9FewZNN44/2CrYvgLB0U/3pMgg2APsmtueBFz2VB0qyA9gBsGnTps9+Zn2wV7A+A5Zuqg9d3iPIlH31VB6oqnZW1WxVzc6s1L+e7RU8aA8eeIw7933CKh01qcszgnng7IntjcB9HT7f8NkreJCs31frujwj2A1sSXJuknXAZcDNHT7fyjAzA9u2GQIDYf2+1OEZQVUdTnIVcCuwBrihqvYkuXJ8/NokzwXmgDOBI0l+BNhaVY90NS9p0tH6/U9yrHTzaP2+1+rVik6XmKiqW4BbFu27duLrjzO6ZCT1wvp9yXcWq3HW70suOidZv6/mGQTq1RCWXQbr99U2g0C9sWxTGgbvEagXlm1Kw2EQqBcuuywNh0GgXli2KQ2HQaBeWLYpDYc3i9UbyzalYTAIGmXZpqSjDIIGWbYpaVI79whsGg9YtinpidoIApvGf5plm5IWW/1BYNP4BSzblLTY6g+Co03jJx1tGt8gyzYlLbb6bxbbNP4JLNuUNGn1nxHYNH6qs844jfPPfpYhIKmBMwIYVNP4odTvS9JRbQQBjH7593wWYP2+pCFa/ZeGBsL6fUlDZRAsE+v3JQ2VQbBMrN+XNFQGwTKxfl/SULVzs3gArN+XNETNBMFQyjZddlnS0DQRBJZtStLxrfp7BJZtStKJrfogsGxTkk5s1QeBZZuSdGKrPggs25SkE2viZrFlm5J0fJ2eESS5KMndSfYmuXrK8ST5rfHxu5K8sKu5uOyyJE3XWRAkWQNcA1wMbAUuT7J10bCLgS3jjx3A73Y1H0nSdF2eEVwA7K2qe6rqceBGYPuiMduBP6yR9wLPSvL5Hc5JkrRIl0GwAdg3sT0/3vdkx5BkR5K5JHP7G206L0ld6TIIMmVfPYUxVNXOqpqtqtmZxltMStJS6zII5oGzJ7Y3Avc9hTGSpA6l6gl/gC/NAyenAv8OvAK4F9gNfHtV7ZkY82rgKuAbgBcBv1VVF5zkcfcDH+tk0stnPfDffU9iQHw9FvL1OMbXYqHP5vU4p6qmXlLp7H0EVXU4yVXArcAa4Iaq2pPkyvHxa4FbGIXAXuD/gO/7DB53xV8bSjJXVbN9z2MofD0W8vU4xtdioa5ej07fUFZVtzD6ZT+579qJrwv4oS7nIEk6sVW/xIQk6cQMgn7s7HsCA+PrsZCvxzG+Fgt18np0drNYkrQyeEYgSY0zCCSpcQbBMkpydpK/T/KhJHuS/HDfc+pbkjVJ3p/kL/qeS9+SPCvJ25N8ePx/5MV9z6lPSX50/HPyb0l2JXla33NaTkluSPJAkn+b2Pe5Sf42yX+MPz97KZ7LIFheh4Efq6ovA74K+KEpK7K25oeBD/U9iYH4TeCvq+p5wPk0/Lok2QC8AZitqq9g9F6ky/qd1bJ7K3DRon1XA++uqi3Au8fbnzWDYBlV1f1Vdfv460cZ/aA/YZG9ViTZCLwauK7vufQtyZnAy4DrAarq8ar6RK+T6t+pwOnjVQqeTmPLz1TVe4D/WbR7O/AH46//APimpXgug6AnSTYDLwD+teep9OktwBuBIycZ14IvBPYDvz++VHZdkmf0Pam+VNW9wK8B/wncDzxcVX/T76wG4fOq6n4Y/WEJPGcpHtQg6EGSM4CbgB+pqkf6nk8fknwj8EBV3db3XAbiVOCFwO9W1QuA/2WJTvtXovG17+3AucAXAM9I8p39zmr1MgiWWZK1jELgbVX1jr7n06OXAK9J8lFGTYu+Lskf9zulXs0D81V19Azx7YyCoVWvBD5SVfur6hDwDuCre57TEPzX0eZd488PLMWDGgTLKEkYXQP+UFX9et/z6VNV/WRVbayqzYxuAv5dVTX7F19VfRzYl+RLx7teAXywxyn17T+Br0ry9PHPzSto+Ob5hJuB7xl//T3Any3Fg3a66Jye4CXAdwEfSHLHeN9PjRfnk14PvC3JOuAePoPVeFerqvrXJG8HbmdUbfd+GltuIsku4EJgfZJ54GeBXwb+NMkVjMLyW5fkuVxiQpLa5qUhSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQTSU5DkQN9zkJaKQSB1LMmavucgnYhBIAFJfiXJD05s/1ySn03y7iS3J/lAku1Tvi9JfnW8Zv4Hkrx2vP/Cce+JP2H0BsI143G7k9yV5AfG4z4/yXuS3DF+jK9Ztn+0NOYbyiQgyQuAt1TV1463P8hoLfhPVNUjSdYD7wW2VFUlOVBVZyS5BLhyPHY9sBt4EfClwF8CX1FVH0myA3hOVf1iktOAf2L0rtBvAZ5WVb80PnN4+niJcmnZuMSEBFTV+5M8J8kXADPAQ4yWP/6NJC9jtFT2BuDzgI9PfOtLgV1V9SlGC4L9A7ANeAR4X1V9ZDzu64Hzklw63v4cYAuj4LhhvBjhu6rqji7/ndI0BoF0zNuBS4HnMloR9TsYhcJXVtWh8Uqpi9sl5gSP97+Lxr2+qm5dPGgcNK8G/ijJr1bVHz71f4L05HmPQDrmRkYroV7KKBQ+h1HPhENJXg6cM+V73gO8dnwPYIZRl7H3TRl3K/C68V/+JPmSJM9Ics74OX6P0cq0LS89rZ54RiCNVdWeJM8E7q2q+5O8DfjzJHPAHcCHp3zbO4EXA3cCBbyxqj6e5HmLxl0HbAZuHy+rvJ9Rm8ELgZ9Icgg4AHz3Uv+7pJPxZrEkNc5LQ5LUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNe7/AftOSWjCIXhLAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.Series(range(1, 11), name='valores').to_frame()\n",
    "df['l1'] = df['valores'].div(df['valores'].abs().sum())\n",
    "df['l2'] = df['valores'].div(df['valores'].pow(2).sum() ** .5 )\n",
    "df['l3'] = df['valores'].div(df['valores'].pow(3).sum() ** (1/3) )\n",
    "ax = df.plot.scatter(x='valores', y='l1')\n",
    "display(df)\n",
    "df.plot.scatter(x='valores', y='l2', ax=ax, color='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The shape of the TF-IDF matrix is:  (3, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF-IDF0_l1</th>\n",
       "      <th>TF-IDF1_l1</th>\n",
       "      <th>TF-IDF2_l1</th>\n",
       "      <th>idf_l1</th>\n",
       "      <th>---</th>\n",
       "      <th>TF-IDF0_l2</th>\n",
       "      <th>TF-IDF1_l2</th>\n",
       "      <th>TF-IDF2_l2</th>\n",
       "      <th>idf_l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <td>0.213077</td>\n",
       "      <td>0.185656</td>\n",
       "      <td>0.123771</td>\n",
       "      <td>1.000000</td>\n",
       "      <td></td>\n",
       "      <td>0.412859</td>\n",
       "      <td>0.478543</td>\n",
       "      <td>0.293607</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natural</th>\n",
       "      <td>0.213077</td>\n",
       "      <td>0.092828</td>\n",
       "      <td>0.123771</td>\n",
       "      <td>1.000000</td>\n",
       "      <td></td>\n",
       "      <td>0.412859</td>\n",
       "      <td>0.239271</td>\n",
       "      <td>0.293607</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>process</th>\n",
       "      <td>0.213077</td>\n",
       "      <td>0.092828</td>\n",
       "      <td>0.123771</td>\n",
       "      <td>1.000000</td>\n",
       "      <td></td>\n",
       "      <td>0.412859</td>\n",
       "      <td>0.239271</td>\n",
       "      <td>0.293607</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>read</th>\n",
       "      <td>0.360770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.693147</td>\n",
       "      <td></td>\n",
       "      <td>0.699030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>everyday</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209562</td>\n",
       "      <td>1.693147</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497120</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evolve</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209562</td>\n",
       "      <td>1.693147</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497120</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>field</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209562</td>\n",
       "      <td>1.693147</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497120</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comprehend</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.693147</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computers</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.693147</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.693147</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.693147</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            TF-IDF0_l1  TF-IDF1_l1  TF-IDF2_l1    idf_l1 ---  TF-IDF0_l2  \\\n",
       "language      0.213077    0.185656    0.123771  1.000000        0.412859   \n",
       "natural       0.213077    0.092828    0.123771  1.000000        0.412859   \n",
       "process       0.213077    0.092828    0.123771  1.000000        0.412859   \n",
       "read          0.360770    0.000000    0.000000  1.693147        0.699030   \n",
       "everyday      0.000000    0.000000    0.209562  1.693147        0.000000   \n",
       "evolve        0.000000    0.000000    0.209562  1.693147        0.000000   \n",
       "field         0.000000    0.000000    0.209562  1.693147        0.000000   \n",
       "comprehend    0.000000    0.157172    0.000000  1.693147        0.000000   \n",
       "computers     0.000000    0.157172    0.000000  1.693147        0.000000   \n",
       "data          0.000000    0.157172    0.000000  1.693147        0.000000   \n",
       "make          0.000000    0.157172    0.000000  1.693147        0.000000   \n",
       "\n",
       "            TF-IDF1_l2  TF-IDF2_l2    idf_l2  \n",
       "language      0.478543    0.293607  1.000000  \n",
       "natural       0.239271    0.293607  1.000000  \n",
       "process       0.239271    0.293607  1.000000  \n",
       "read          0.000000    0.000000  1.693147  \n",
       "everyday      0.000000    0.497120  1.693147  \n",
       "evolve        0.000000    0.497120  1.693147  \n",
       "field         0.000000    0.497120  1.693147  \n",
       "comprehend    0.405122    0.000000  1.693147  \n",
       "computers     0.405122    0.000000  1.693147  \n",
       "data          0.405122    0.000000  1.693147  \n",
       "make          0.405122    0.000000  1.693147  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Usando a norma l1\n",
    "vectorizer_l1_norm = TfidfVectorizer(norm=\"l1\")\n",
    "tf_idf_matrix_l1_norm = vectorizer_l1_norm.fit_transform(preprocessed_corpus)\n",
    "df = show_tlidf_matrix(tf_idf_matrix_l1_norm, vectorizer_l1_norm)\n",
    "df.columns = [c + '_l1' for c in df.columns]\n",
    "\n",
    "##### Adicionando a norma l2\n",
    "_df = tl_idf_default.copy()\n",
    "_df.columns = [c + '_l2' for c in _df.columns]\n",
    "df['---'] = ''\n",
    "pd.concat([df, _df], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N-grams e Max features com TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The shape of the TF-IDF matrix is:  (3, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF-IDF0</th>\n",
       "      <th>TF-IDF1</th>\n",
       "      <th>TF-IDF2</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language process</th>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natural</th>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natural language</th>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natural language process</th>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>process</th>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           TF-IDF0   TF-IDF1   TF-IDF2  idf\n",
       "language                  0.408248  0.666667  0.408248  1.0\n",
       "language process          0.408248  0.333333  0.408248  1.0\n",
       "natural                   0.408248  0.333333  0.408248  1.0\n",
       "natural language          0.408248  0.333333  0.408248  1.0\n",
       "natural language process  0.408248  0.333333  0.408248  1.0\n",
       "process                   0.408248  0.333333  0.408248  1.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_n_gram_max_features = TfidfVectorizer(norm=\"l2\", analyzer='word', ngram_range=(1,3), max_features = 6)\n",
    "tf_idf_matrix_n_gram_max_features = vectorizer_n_gram_max_features.fit_transform(preprocessed_corpus)\n",
    "show_tlidf_matrix(tf_idf_matrix_n_gram_max_features, vectorizer_n_gram_max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Matrix Shape:  (6, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n-grams</th>\n",
       "      <th>qtd0</th>\n",
       "      <th>qtd1</th>\n",
       "      <th>qtd2</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>process</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>natural language process</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>natural language</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>natural</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>language process</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>language</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    n-grams  qtd0  qtd1  qtd2  Total\n",
       "0                   process     1     1     1      3\n",
       "1  natural language process     1     1     1      3\n",
       "2          natural language     1     1     1      3\n",
       "3                   natural     1     1     1      3\n",
       "4          language process     1     1     1      3\n",
       "5                  language     1     2     1      3"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mostrando o resultado do CountVectorizer para comparar\n",
    "vectorizer_max_features = CountVectorizer(analyzer='word', ngram_range=(1,3), max_features = 6)\n",
    "bow_matrix_max_features = vectorizer_max_features.fit_transform(preprocessed_corpus)\n",
    "show_bow_matrix(bow_matrix_max_features, vectorizer_max_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitações do vetorizador TF-IDF\n",
    "\n",
    "**- Pró**\n",
    "    - Oferece uma melhoria em relação ao `CountVectorizer` ao dimensionar o pesos dos termos que ocorrem com menos frequência.\n",
    "    - É computacionalmente rápido.\n",
    "  \n",
    "**- Contra** \n",
    "    -  Baseia-se na análise lexical e não leva em conta coisas como:\n",
    "       - co-ocorrência de termos\n",
    "       - semântica\n",
    "       - contexto associado a termos\n",
    "       - posição de um termo em um documento \n",
    "    - Depende do tamanho do vocabulário <sub>(ficará muito lento com tamanhos de vocabulário grandes)</sub>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similaridade de documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introdução\n",
    "\n",
    "Após aprender algumas técnicas de representação, vamos aplicá-las para calcular a distância (similaridade) entre documentos de texto usando **Similaridade por Cosseno**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Premissa:**\n",
    ">\n",
    ">Se as **palavras** usadas em dois documentos forem **semelhantes**, isso indica que os **documentos** são **semelhantes** também."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Como calcular**\n",
    "\n",
    "\n",
    "$\n",
    "cos\\theta = \\dfrac{A \\cdot B}{||A|| \\space ||B||} = \\dfrac{\\Sigma_{i=1}^{n} A_i \\times B_i}{\\sqrt{\\Sigma_{i=1}^{n} A_i^2}  \\times \\sqrt{\\Sigma_{i=1}^{n} B_i^2}}\n",
    "$\n",
    "\n",
    "- Considerações\n",
    "  - A e B são vetores de dimensões iguais\n",
    "  - Se `cos $\\theta$ = 1`: documentos A e B são iguais\n",
    "  - Se `cos $\\theta$ = -1`: documentos A e B são totalmente diferentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para calcular Similaridade por Cosseno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vector1, vector2):\n",
    "    vector1 = np.array(vector1)\n",
    "    vector2 = np.array(vector2)\n",
    "    return np.dot(vector1, vector2) / (np.sqrt(np.sum(vector1**2)) * np.sqrt(np.sum(vector2**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similaridade por Cosseno usando o CountVectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A similaridade por cosseno entre os documentos 0 e 1 é: 0.6324555320336759\n",
      "A similaridade por cosseno entre os documentos 0 e 2 é: 0.6123724356957946\n",
      "A similaridade por cosseno entre os documentos 1 e 2 é: 0.5163977794943223\n"
     ]
    }
   ],
   "source": [
    "for i in range(bow_matrix.shape[0]):\n",
    "    for j in range(i + 1, bow_matrix.shape[0]):\n",
    "        print(f\"A similaridade por cosseno entre os documentos {i} e {j} é: \" + \n",
    "              f'{cosine_similarity(bow_matrix.toarray()[i], bow_matrix.toarray()[j])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os documentos 0 e 1 são os mais similares e os documentos 1 e 2 são os mais diferentes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similaridade por Cosseno usando o TfIdfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 1 is:  0.39514115766749125\n",
      "The cosine similarity between the documents  0 and 2 is:  0.36365455673761865\n",
      "The cosine similarity between the documents  1 and 2 is:  0.2810071916500233\n"
     ]
    }
   ],
   "source": [
    "for i in range(tf_idf_matrix.shape[0]):\n",
    "    for j in range(i + 1, tf_idf_matrix.shape[0]):\n",
    "        print(\"The cosine similarity between the documents \", i, \"and\", j, \"is: \",\n",
    "              cosine_similarity(tf_idf_matrix.toarray()[i], tf_idf_matrix.toarray()[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os documentos 0 e 1 são os mais similares e os documentos 1 e 2 são os mais diferentes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vetorização One-Hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence2 = [\"We are reading about Natural Language Processing Here\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    We are reading about Natural Language Processi...\n",
       "dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus2 = pd.Series(sentence2)\n",
    "corpus2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['read natural language process']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing with Lemmatization here\n",
    "preprocessed_corpus2 = preprocess(corpus2, keep_list = [], stemming = False, stem_type = None,\n",
    "                                lemmatization = True, remove_stopwords = True)\n",
    "preprocessed_corpus2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo o vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['language', 'read', 'process', 'natural']\n"
     ]
    }
   ],
   "source": [
    "set_of_words = set()\n",
    "for word in preprocessed_corpus[0].split():\n",
    "    set_of_words.add(word)\n",
    "vocab = list(set_of_words)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encontrando a posição de cada palavra no vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'language': 0, 'read': 1, 'process': 2, 'natural': 3}\n"
     ]
    }
   ],
   "source": [
    "position = {}\n",
    "for i, token in enumerate(vocab):\n",
    "    position[token] = i\n",
    "print(position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciando a matriz one-hot\n",
    "\n",
    "> Note here every row in the matrix corresponds to the One Hot vector for an individual term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_matrix = np.zeros((len(preprocessed_corpus2[0].split()), len(vocab)))\n",
    "display(one_hot_matrix)\n",
    "one_hot_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>read</th>\n",
       "      <th>process</th>\n",
       "      <th>natural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   language  read  process  natural\n",
       "0       0.0   1.0      0.0      0.0\n",
       "1       0.0   0.0      0.0      1.0\n",
       "2       1.0   0.0      0.0      0.0\n",
       "3       0.0   0.0      1.0      0.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# representação com DataFrame\n",
    "pd.DataFrame(one_hot_matrix, columns=position.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preenchendo a Matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, token in enumerate(preprocessed_corpus2[0].split()):\n",
    "    one_hot_matrix[i][position[token]] = 1\n",
    "one_hot_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minha Versão..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>read</th>\n",
       "      <th>process</th>\n",
       "      <th>natural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [language, read, process, natural]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>read</th>\n",
       "      <th>process</th>\n",
       "      <th>natural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language read process natural\n",
       "0        0    1       0       0\n",
       "1        0    0       0       1\n",
       "2        1    0       0       0\n",
       "3        0    0       1       0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cria df base com o vocab\n",
    "df = pd.DataFrame(columns=vocab)\n",
    "display(df)\n",
    "\n",
    "# cria matrix one-hot com todas palavras\n",
    "df_to_concat = pd.get_dummies(preprocessed_corpus2[0].split())\n",
    "\n",
    "# filtra para ter apenas as colunas \n",
    "df_to_concat = df_to_concat[df_to_concat.columns.intersection(df.columns)]\n",
    "pd.concat([df, df_to_concat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Armazene todas as perguntas do corpus em uma lista\n",
    "2. Armazene todas as respostas correspondentes do corpus em uma lista\n",
    "3. Vetorize e pré-processe os dados da pergunta\n",
    "4. Vetorize e pré-processe a consulta do usuário\n",
    "5. Avalie a pergunta mais semelhante à consulta do usuário usando a semelhança de cosseno\n",
    "6. Devolva a resposta correspondente à pergunta mais semelhante como uma resposta de bate-papo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# carregando o arquivo de perguntas e respostas de equipamentos eletrônicos da Amazon\n",
    "# em listas distintas\n",
    "import ast \n",
    "questions = []\n",
    "answers = [] \n",
    "with open('qa_Electronics.json','r') as f:\n",
    "    for line in f:\n",
    "        data = ast.literal_eval(line) # function to convert the rows from a string to a Python dictionary\n",
    "        questions.append(data['question'].lower())\n",
    "        answers.append(data['answer'].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is this cover the one that fits the old nook color? which i believe is 8x5.',\n",
       " 'does it fit nook glowlight?',\n",
       " 'would it fit nook 1st edition? 4.9in x 7.7in ?',\n",
       " \"will this fit a nook color that's 5 x 8?\",\n",
       " 'will this fit the samsung galaxy tab 4 nook 10.1',\n",
       " 'does it have a flip stand?',\n",
       " 'does this have a flip stand',\n",
       " 'also fits the hd+?',\n",
       " 'does it have 2 positions for the reader? horizontal/vertical thank you kwod',\n",
       " 'is there a closure mechanism? bands, magnetic, etc.?',\n",
       " 'how far out does the arm extend?',\n",
       " 'can you mount a sound bar using the external \"stick\" arms vertically hanging below the lcd monitor (27 inch)?',\n",
       " 'my tv has a vesa 200x200 bolt pattern and i need it to extend to 24 inches. with the extension, will this wall mount fit my bolt pattern?',\n",
       " 'my vizio has 200 ht x 600 width mounting holes. will this mount handle that?',\n",
       " 'will it fit vizio tvs?',\n",
       " 'does it work well with 39 inch magnavox tv',\n",
       " 'can i use it on a tv with vesa 100 x 100?',\n",
       " 'will it mount a 32\" vizio? the bolts in back are 20\" apart will the bracket fit that?? last mount i bought didn\\'t and don\\'t want to buy extension.',\n",
       " 'will this work with viso vx37l?',\n",
       " 'can it be used for vizio 39\" class led smart tv | e390i-a1?',\n",
       " 'hi, does it work with macbook air 13.3\" latest model? thanks',\n",
       " 'does this cable enable a macbook air 11 inch late 2010 model to connect to a tv?',\n",
       " 'does it work with macbook air mid2012?',\n",
       " 'hi! does it work on macbook pro with retina display 13.3 inch (the latest one) ?',\n",
       " 'does this work with mac mini?',\n",
       " 'is it working with pro retina early 2013 ?',\n",
       " 'will this adapter enable my mac airbook to connect to a lcd monitor',\n",
       " 'hello, will this cable work a 2012 model macbook pro ?',\n",
       " 'hello, what year macbook pro do you use this cable for?',\n",
       " 'does this item come with a charger?',\n",
       " 'can my library of books from kindle be accessed by the nook?',\n",
       " 'why is it more expensive here than direct from b&amp;n? is there anything different about the one sold here on amazon?',\n",
       " 'can you buy books from amazon for the nook ereader',\n",
       " 'does it have a light',\n",
       " 'does it have a slot for sd card?',\n",
       " 'is it possible to read using this product at night?',\n",
       " 'is the nook ok for a reader with poor eyesight ? is enlarged print an easy option ?',\n",
       " 'wi fi only?',\n",
       " 'can the books for the nook be purchase on amazon or do we have to go to barnes &amp; noble?',\n",
       " 'can i read my ebooks from amazon on my nook?',\n",
       " 'can i download books i need for school? collage/university',\n",
       " 'what does wifi only mean? can you transfer through your computer also?',\n",
       " 'does this mean you can only use this if you have wifi? my daughter doesnt want her on the internet.',\n",
       " 'how do i download king james bibleverser in mysimple touch reader',\n",
       " 'why is it more expensive here than on b&amp;n website ($99) is there something added?',\n",
       " 'can i transfer my previously purchased epub books from another source?',\n",
       " 'can anyone compare the nook glowlight to the nook color for me? i know it is not a tablet, so ignore that part, just compare the ereader part',\n",
       " 'is the dictionary feature available on this?',\n",
       " 'what is the screen dimensions of the glowlight',\n",
       " 'do you have to be online to access your library or just to shop?',\n",
       " 'can i transfer epub books from my computer onto a nook?',\n",
       " 'does this version have a camera?',\n",
       " 'does this e reader read georgian language, not all the gadgets support my language and if you have any information about it please tell me :)',\n",
       " 'can kobo books be transfered to the nook glowlight?',\n",
       " 'does this nook play games',\n",
       " 'does it get the internet?',\n",
       " 'can ir download from a pc',\n",
       " 'can you use a table of contents to go directly to a chapter',\n",
       " 'does this model have an sd card slot?',\n",
       " 'is it elderly friendly?',\n",
       " 'can you download books without wifi',\n",
       " 'is this the newest b&amp;n e-reader? if so, change the picture - it looks unprofessional.',\n",
       " 'does this work with kindle books?',\n",
       " 'do i have to have a micro sd card to use it?? in \"device info\"it is telling me i have no available storage.',\n",
       " 'how well can you see the screen in sunlight?',\n",
       " 'cam',\n",
       " 'putting books on shelves',\n",
       " 'can this nook read aloud?',\n",
       " 'what kind of manufacturer warranty comes with this device? is there anything that covers it right out of the package?',\n",
       " \"does the nook hd 7'' use the same charger that almost all smartphones use? thanks\",\n",
       " 'do you need to be connected to the internet to use for reading pre installed books ?',\n",
       " 'should nook hd be on to charge the battery?',\n",
       " 'can i install and run my own apps from sd or usb flash on it?',\n",
       " 'i purchased the nook hd, is it any different from the nook color? and which is better?',\n",
       " 'what is the average life of the nook hd?',\n",
       " 'does nook hd come with barnes &amp; nobel one year warranty, or do you receive a shorter warranty.',\n",
       " 'which color is this nook hd (asin 1400501520)? is it the \"snow\" or \"smoke\" colored nook hd?',\n",
       " 'what kind of usb connection does it have? some seem to have a very wide 30-pin...but i thought some models have the mini-usb (android phone type).',\n",
       " 'can i use the hd 7\"16gb tablet to borrow books from my public library?',\n",
       " 'does the battery life vary from nook hd 8 gb vs 16gb?',\n",
       " 'is there a way to download books and movies from amazon prime to nook hd?',\n",
       " 'what are the measurement of the nook 7\"hd 16gb',\n",
       " 'is it compatible with ebooks bought from booksamillion?',\n",
       " 'i have a new nook hd purchased last week. has anyone had issues with the their device not holding a charge?',\n",
       " 'can i port my kindle books to this platform?',\n",
       " 'why is it 179.99? everywhere else is 269.99...what does shrink wrapped mean? what make it $90 cheaper here?',\n",
       " 'can you use word2010 and onenote2010 on the nook hd+ ? if so do i need any kind of adapters etc, apps or new software? or just sd card.',\n",
       " 'can i download the kindle app for this?',\n",
       " 'which version of android does this run?',\n",
       " 'is the 16gb the physical memory or expandable.',\n",
       " 'does any other cable beside the 30 pin work to charge hd+?',\n",
       " 'can you download netflix?',\n",
       " 'camera',\n",
       " 'are their games like mine craft?',\n",
       " 'how easy is this to use in direct sunlight? glare? or no?',\n",
       " 'does it come with the two cords and the case?',\n",
       " 'is the cover case included that is shown in the top picture?',\n",
       " 'does it come with a power cord? anything else?',\n",
       " 'i plug it in &amp; the light is green for 3sec then light turns orange. i pressed \"nook button\" &amp; power button simultaneously for 20 sec but no power stil',\n",
       " 'why is it slow',\n",
       " 'it looks as if it takes an i-phone charger...does it take special charger or same as i-phone?',\n",
       " 'can i use my skype account on this nook?',\n",
       " 'how much ram does it have? what is the processing speed?',\n",
       " 'can you use this for downloading college class textbooks on this rather than buying the actual books?',\n",
       " \"why are some e-books available on kindle but not on nook? i'm thinking of getting an e-reader and i was looking at the ebook selection on amazon vs b&amp;n.\",\n",
       " 'rooted nook experience? please share your experience with your rooted nook: how long did it take you to root?',\n",
       " 'can you use an amazon gift card to purchase books on the nook? or does it have to be a barnes and noble gift card only?',\n",
       " 'does it come with a speakerphone',\n",
       " 'can i use this to control my samsung television if i install android on an sd card?',\n",
       " 'facebook: can you get facebook on the nook tablet',\n",
       " 'nookcolor accessories? does anyone know of a good dealer (other than b&amp;n) for nookcolor accessories?',\n",
       " 'nook color $249 vs galaxy tab wifi $350: is nook color at $250 still a better deal as compared to galacxy tab, assuming i will root it ?',\n",
       " 'only 5gb of internal memory usable? do other users see the same thing, only 5gb available?',\n",
       " 'can you read ths in the sunlight outside?',\n",
       " 'is it user friendly',\n",
       " 'what does it mean by wifi? does that mean i can only read books when i have wifi or does that mean i can only download books when i have wifi?',\n",
       " 'can you navigate the internet? can you send emails',\n",
       " 'can i play facebook games on it',\n",
       " 'can i download the kindle app?',\n",
       " 'my nook will not charge. when you plug it in the light turns on green, then immediately goes orange, then off. help',\n",
       " \"just got my nook and of course it was turned off and needed to be charged, but can you turn it on while it's charging ? if so then why can't mine turn\",\n",
       " 'is the nook only wi fi',\n",
       " 'is the nook 3g free ? is the nook 3g free, like the kindle?',\n",
       " 'nook in the uk? the only problem is that i live in the uk and have heard that it may not be compatible?',\n",
       " 'nook tablet or kindle fire?',\n",
       " 'does the nook have a usb port?',\n",
       " 'dose it have a talking gps',\n",
       " 'can i watch hulu shows or hulu plus? does nook spport youtube videos and vevo videos?',\n",
       " 'can you see what you are reading if you are in sunlight??',\n",
       " \"i can't set up account information. says billing address is not recognized\",\n",
       " 'does it come with a wall charge r? i have no laptop or pc to charge it by',\n",
       " 'can you download books from amazon to the nook hd?',\n",
       " 'the screen on my nook stays blank, how do i fix that?',\n",
       " 'who makes covers for nook bntv250',\n",
       " 'does it have google play?',\n",
       " 'is the nook hd?',\n",
       " 'can you read in sun light',\n",
       " 'i have many books on my kindle but i would like to transfer them to my nook....is there an app? i also would like to have the candy crush app..is ther',\n",
       " 'do you have to use wifi to read them or just download and read?',\n",
       " 'does an i tunes gift card work for nook or do you need to purchase barnes and nobel gift cards, to give as gift?',\n",
       " 'how long does a battery last in a nook and can you buy replacements?',\n",
       " 'my child is 5+ and navigates well on smartphone. is this better than a nabi tablet?',\n",
       " 'can you surf the web?',\n",
       " 'can i get on the internet',\n",
       " 'has anyone connected a hd webcam successfully?',\n",
       " 'does the optical out work with watching bluray movies? i doubt it, but can someone confirm?',\n",
       " 'compatible with tivo? will this work with it?',\n",
       " 'flatscreen not internet ready - will it work with this unit? will hooking this unit up to my tv allow me to use my wifi from the house for netflix?',\n",
       " \"i can't get the player to play 3d blurays even after updating the firmware. tv plays 3d from comcast and is set to autodetect 3d signals.help?\",\n",
       " \"i'm going to buy a sony google tv. do i still need something like sony nsz-gt1 to watch netflix or browsing the net on my tv?\",\n",
       " 'can i connect to my direct tv box to connect the dtv box to internet? basically use the sony as a modem for the dtv box?',\n",
       " 'will google chrome os recognise the dvd player on this device.',\n",
       " 'so does this sony nsz-gt1 have a dvr built in? and what kind of jacks does it have on the back? and where can i down load an owners manual at?',\n",
       " 'i would like to know if the sony nsz-gt1 is having the same problems as the logitech revue with netflix? i am very interested in adquiring the sony nsz-gt1, but before place my order i would like to know whether or not sony nsz-gt1 is having the same...',\n",
       " 'will this hdd work in an ipod classic 6th generation model?',\n",
       " 'will this hdd work in a ipod classic 5th generation model a 1136?',\n",
       " 'will this drive work with a 4th generation ipod (click wheel)?',\n",
       " 'is this hard drive new? what kind of packaging does it come in?',\n",
       " 'left-handed compatibility? does anyone know if this will be able to be oriented for left-handers?',\n",
       " 'does the case allow you to use the camera/video without removing it? (i didn\\'t see a \"hole\" on the backside)',\n",
       " 'does this fit the new ipad air?',\n",
       " 'would a nexus 10 fit in this wonderful case?',\n",
       " 'ipad 2.0: will this hold an ipad 2 or will they be maing a new version?',\n",
       " 'replacement paper: what type of moleskine pad do i order when i want to refill it?',\n",
       " 'will it ever ship? anyone order this and have it ship yet, or perhaps you received it already?',\n",
       " \"ouch, pricey! man, that's a little much for a paper based cover, unless i am mis-reading the description and the product pic is wrong, it's paper...right?\",\n",
       " 'replacement notebooks: has anyone seen a price on what replacement notebooks will cost?',\n",
       " 'can be run on apple computer with graphic card ati radeon hd 5870',\n",
       " 'is the screen matte or gloss?',\n",
       " 'does it display any sort of ghosting when playing video games or when scrolling?',\n",
       " 'what are the dimensions of just the monitor panel (width and height)?',\n",
       " 'does the ccfl lcd panel generate excessive heat?',\n",
       " 'how much does this monitor weigh?',\n",
       " 'does this monitor have a warranty?',\n",
       " 'considering it as a \"work\" monitor. i work a lot with large financial models, docs (view/edit), maybe watch some movies. tips? thoughts? thanks!',\n",
       " 'has anyone used this monitor with the nvidia gtx 980 ?',\n",
       " 'how much does it weigh? i would want to mount it on an adjustable arm and want to know if the typical arm can take it.',\n",
       " 'i will like to know does it save the file in avi format?',\n",
       " 'hi, does it save the file in avi format?',\n",
       " \"what's the diameter, is it color or b&amp;w, does it have onboard storage like an sd card?\",\n",
       " 'do it show in black and white , are in coller',\n",
       " \"for the sake of knowing how it'll fit into my decor... it would be nice to know the diameter of the clock... ??? note: i've already ordered it... so it's just for curiosity's sake i ask...\",\n",
       " 'power supply was not included ?',\n",
       " 'where is the power supply for my gw security gwclk20 420tvl',\n",
       " 'supports a acer aspire computer e5 751p?',\n",
       " 'will this work on acer aspire one running linux mint 17?',\n",
       " 'does it work on windows 8.1?',\n",
       " 'is this compatible with mac os 10.4.11?',\n",
       " 'can you use this drive with an acer aspire v5?',\n",
       " 'will it run on windows 8 ?',\n",
       " \"it won't burn disks...is there a driver i can install for this?\",\n",
       " 'can it play games for computer',\n",
       " 'does it work on windows 8',\n",
       " 'does it work with an imac?',\n",
       " 'windows 7 compatible external usb dvd/cd f netbook: will this dvd/cd work with windows 7?',\n",
       " 'i want to play language dvds on my hp notebook with windows xp. is this all i need to do that?',\n",
       " 'will this work with galaxy 10.1 tablet?',\n",
       " 'currently using an mp3 player to listen to music in my truck (no cd player). i plug in to the usb port on the console. would this work the same way?',\n",
       " 'usb teac cd-224e dvd/cd will play cds but not dvds on windows 8.1 dell laptop. any fix?',\n",
       " \"isn't recognized on my laptop, is there an external site to download the driver?\",\n",
       " \"are these compatible with surefire lights? the lifepo4 say they aren't compatible, but are these lipos going to function properly?\",\n",
       " 'surefire?',\n",
       " 'will these batteries work in the bushnell range finder?',\n",
       " 'will these work on an aim 5mw green laser',\n",
       " 'will these batteries work on the streamlight twin task 2l?',\n",
       " 'does the charger work for aa/aaa batteries as well?',\n",
       " 'how about the mag tac of maglite led light? does it works with it?',\n",
       " 'will these fit in an gander mtn. 350 lumen flashlight? it uses cr123a batteries. thanks in advance.',\n",
       " 'will these batteries work in a steamlight pro tac hl? it uses the cr123a battery.',\n",
       " 'are these batteries work in a steamlight pro tac hl? it uses the cr123a battery.',\n",
       " 'skype',\n",
       " 'do you carry this product in white ?',\n",
       " 'would this product be useful on a ipod touch 64 gb. model # mc011ll',\n",
       " 'can i use this with a laptop as well? my inbuilt laptop mic is not functioning properly,so i was hoping that i can use this as an external replacement',\n",
       " 'ipod touch 1st generation: will this product work with the ipod touch 1st generation?',\n",
       " 'love the card, works great with 1520 but i received a usb flash drive. what is it for?',\n",
       " 'hi, can you tell me where this micro sd card is made? and does it really work fine on a nokia lumia 1520?',\n",
       " 'what is the difference with other sd on the market? better transference rates?',\n",
       " 'i thought 1520 could only capable of using 32 gig',\n",
       " \"is this guarenteed to work with the 1520? i bought a diff class 10 card with doesen't.\",\n",
       " \"what is the usb flash drive for? i didn't see it mentioned in the specs when i bought it.\",\n",
       " 'will this work in italy?',\n",
       " 'can this be used in korea or japan?',\n",
       " 'is the power entering through the usb entrance? or can you only take power from the usb port?',\n",
       " 'wll this work in france?',\n",
       " 'will this work in india?',\n",
       " 'will this work in the southern caribbean?',\n",
       " 'will this work in the dominican?? thanks for your time!',\n",
       " 'has anyone tried charging a nexus tablet with this?',\n",
       " 'will this work in nepal? i only see one configuration in the pictures so unsure how it is universal.',\n",
       " 'hi. does this work for samsung galaxy note2?',\n",
       " 'this product works with galaxy s4?',\n",
       " 'hello, can this be used with a samsung galaxy note? i have a siii, but my wife has a galaxy note, so i want to know if this works with both phones.',\n",
       " 'will this card work with other devices or gopro only?',\n",
       " 'can it be used for go pro white or is it just for the black?!',\n",
       " 'does this work well for the gopro 4 silver?',\n",
       " 'does it work for a gopro hero?',\n",
       " 'will this work for the gopro 4 silver?',\n",
       " 'can i use this on psp',\n",
       " 'got today. \"sd err\" once inserted on the hero3. any ideas? solutions?',\n",
       " 'can this be used with other android smartphone or devices and if not now can it be reformatted',\n",
       " 'i just bought this sandisk for my samsung galaxy s4 phone. however, neither of the disks fit on the back of the phone. am i doing something wrong?',\n",
       " 'can i use it on a galaxy s3? or in a camera? anyone try it yet?',\n",
       " 'can be used on pc or laptop?',\n",
       " 'does the adapter come with sd micro?',\n",
       " 'can you download/save apps in this card?',\n",
       " 'does it work in other samsung phones?',\n",
       " 'can it be used in a camera? (cannon powershot in a adapter)',\n",
       " 'can be used for gopro camera?',\n",
       " 'is this sd card compatible with samsung galaxy s4 mini?',\n",
       " 'is this card going to work with my galaxy s3?',\n",
       " 'is this sd card compatible with samsung galaxy s4 mini?',\n",
       " 'will this work in a samsung s4 mini?',\n",
       " 'will this work in a samsung ace 3 s7275?',\n",
       " 'comes in sealed blister ??? kingston its carton and all ??? thanks for replying',\n",
       " 'is possible to use in a m2 slot',\n",
       " 'comes in its original retail packaging? blister?',\n",
       " 'can you use this with other devices other than the galaxy phone?',\n",
       " 'how long will it take to arrive',\n",
       " 'this memory card is for any cell phone as a bold 9700?',\n",
       " 'can this be used in a android tablet',\n",
       " 'is mini hdmi same as micro hdmi',\n",
       " 'is this work with canon rebel t3?',\n",
       " 'can i trim back plastic in mini side a bit? i have a mini micro port that is a bit deeper.',\n",
       " 'is this only for cameras? can it be used for a tablet that has a mini hdmi output?',\n",
       " 'will this work for a canon eos 70d?',\n",
       " 'does it work on canon vixia hf r400?',\n",
       " 'is the camera end a type d?',\n",
       " 'will this work with a canon powershot sx510 hs camera type a connector at on end and type c at the other ?',\n",
       " 'works with canon 60d? im looking to buy a 60d thats why i ask.',\n",
       " 'are there different sizes of mini hdmi',\n",
       " 'i have a question about this product. is that product will connect to tv and desktop right?',\n",
       " 'will it work with lg led tv?',\n",
       " 'what is the awg wire size? at least 24awg?',\n",
       " \"what's the length of this cord?\",\n",
       " 'can i use this cable for my garmin nuvi to charge in while in the car using the usb outlet instead of the cigarette lighter outlet?',\n",
       " \"does this fit the garmin 1300 gps? why the conflicting answers? does it fit or doesn't it?\",\n",
       " 'will this work with my garman nuvi 1350?',\n",
       " 'is it mini or micro usb connector cable and can it be used on a nuvi 54lm gps',\n",
       " 'will this card work in my 1450 lmt model?',\n",
       " 'will this fit in my garmin 40?',\n",
       " 'will this card work in my 1490 lmt model?',\n",
       " 'will this work with garmin nuvi 1300 series?',\n",
       " 'will t his work on my nuvi 1390?',\n",
       " 'do i need to buy a microsdhc card reader for this product? as my pc only has usb port.',\n",
       " 'willl this work with garmin nuvi 50lm 5\"?',\n",
       " 'does this go all the way into the side slot on the nuvi 1450, or will it stick out of the side? is an adapter needed?',\n",
       " 'is this compatible with the nuvi1 400 series',\n",
       " 'does this also support lower resolution...example: computer resolution is not as high as hdtv resolution?',\n",
       " 'whats the gauge of the cable?',\n",
       " 'are these specs for real? 1080p-2160p, 4k, 3d, deep color, truehd, cl3, and 800hz',\n",
       " 'is this cable approved for in wall installations?',\n",
       " 'does this support desktop computer to hdtv1080i?',\n",
       " 'how many gigabytes per second? gbps?',\n",
       " 'as per stated: premium 50 foot high speed hdmi cable for your sony bravia kdl-40ex400 hdtv, can i use this in any other tv devices such as samsung?',\n",
       " \"how do you know its working in there? i bought a lens cleaner from wal mart and it took it in, then said 'check cd' and then was just blank...it came with no directions so i thought of getting a different one...that one i guess wasnt for a car cd...\",\n",
       " 'does this cd player cleaner work with car cd players',\n",
       " 'i went to track 3 as instructed. then said to press \"play\". i don\\'t have a \"play\" button on my cd. nothing moved. how do i get the disc to clean?',\n",
       " 'i have heard that if your cd player is \"push in\" as opposed to a tray that these cleaners can get stuck in the player - true? i have a bose radio/cd',\n",
       " 'does this product work on slot style cd players?',\n",
       " '2001 ford explorer,cd slot drive,started shuffle to different tracks on audio cd.any one with this problem and will this fix it?',\n",
       " 'will it clean a cd player in a mercedes s550?',\n",
       " 'can this work on a car stereo. cuz i bought it and inserted it into my car stereo to clean butthe track 2 that was suppose to do the cleaning did not.',\n",
       " \"why does it say to skip to track 3 when music stops? why doesn't it say to go to track 2?\",\n",
       " 'will it work on dvd players as well...?',\n",
       " 'does this work with an iphone?',\n",
       " 'what equipment is needed to play tapes in car with only cd?',\n",
       " 'any issues with auto-reverse? i purchased the rca and it will only play for a few minutes before it starts to constantly reverse itself.',\n",
       " 'i purchased this, but when i use it in car, only one speaker out of six works. should this happen or is unit defective? with radio &amp;cd player, all',\n",
       " 'what can i do if my car doesnt have a cassette input. all i have in a cd player and car charger adapter. what can i do to play music from my cellphone',\n",
       " 'how long is the cord?',\n",
       " 'will these work in my dcr-trv730 hi8 camcorder?',\n",
       " 'could i use this in a vintage super 8?',\n",
       " 'how many are in each pack? (for new ones)',\n",
       " 'are the 2 drive gears of the tape 1 3/4 inches center to center ?',\n",
       " 'are these the same as minidv tapes, or are they slightly different?',\n",
       " 'will these tapes work on a sony video hi8 xr ccd-trv85 camcorder?',\n",
       " 'will these work on a sony handycam video hi8 ccd-trv138/trv338 digital 8 dcr-trv280',\n",
       " 'crazy quesion but are these the fat tapes or the thin ones? i am looking for the fat camcorder tapes',\n",
       " 'are these the right tapes for a sony dcr-trv-120 camera?',\n",
       " 'will the maxell 8mm work on a samsung model#sca30 ?',\n",
       " 'would these work on a boogie board?',\n",
       " 'will this work on samsung galaxy tab 4 or galaxy tab s?',\n",
       " 'will this stylus work on iphones?',\n",
       " 'can i use this stylus with my hp touch screen laptop',\n",
       " 'will these work with an autel maxidas?',\n",
       " 'will this work on a kindle? i like to do jig saw puzzles and was looking for a stylus like this.',\n",
       " 'will this stylus work on a transformer infinity?',\n",
       " 'will the palm work with the ipad? first virsion',\n",
       " 'will it work on a kindle fire? been looking for a stylus that i can use to take notes. thanks.',\n",
       " 'do u need to already have phone service for this to work',\n",
       " 'can you hook this to a phone jack and will it transmit to a modem?',\n",
       " \"is the rca wireless phone jack compatible with at&amp;t u-verse? i was using an easy jack before i upgraded to u-verse and now it doesn't work.\",\n",
       " 'can this be used for a credit card machine?',\n",
       " 'does this product work 220v electricity grid?',\n",
       " 'will this interfere with a powerline ethernet av adapter system (same concept, but for ethernet signal)? i use trentnet powerline av adapters.',\n",
       " 'is it compatable with a voip phone system or an hd tivo dvr?',\n",
       " 'will this work with a rotary phone?',\n",
       " 'is case included',\n",
       " 'are these vhs camcorders in really good condition and guaranteed?',\n",
       " 'does this camera use the full size vhs tape or the small ones. i am looking for full size.',\n",
       " 'is this pal or ntsc?',\n",
       " 'will this cd cleaner work in a car cd player',\n",
       " 'will this device work on a cd changer in which discs are stored vertically? sony 400cd megastorage?',\n",
       " \"reviews all seem to be for cd players. photo of product says it's for dvd and other disk players, too. does it work well for dvds?\",\n",
       " 'will the cleaner work for mac optical drive?',\n",
       " 'will this work in a multi-disc (6) car cd player? would you have to run it in each of the 6 cd \"positions\"?',\n",
       " 'has anyone used this on a wii?',\n",
       " 'can you use it for a car cd player? player came with the car.',\n",
       " 'does this work on a car cd player? thank you!',\n",
       " \"i have a mazda 3 and after putting an old cd in, it says 'check cd' and wont read/ play... its a slot 1 disc player.... will it work for my mazda?\",\n",
       " 'will it work for a laptop?',\n",
       " 'is this unit wall mountable and does it run on batteries?',\n",
       " 'my unit only says \"error\" when a call comes in. do you have any suggestions?',\n",
       " 'my laptop is dell inspiron 15 .does this cable fit for my dell?',\n",
       " 'need to connect macbook pro to dorm room ethernet. will this fit a mac?',\n",
       " 'is this cord used to connect mybtablet to my flat screen tv so i can watch the internet on my tv from being plugged in to my tablet?',\n",
       " 'compatible with 30 ft. away .http://www.amazon.com/gp/product/b00... ?',\n",
       " 'does this work for sony ps3 to router',\n",
       " 'will it work with my majic jack?',\n",
       " \"is ethernet the same as lan? is this what i'd use to connect my router to my wired blu ray player?\",\n",
       " \"is this an ethernet cable? can i connect this to my university's ethernet port and get lan access on my computer?\",\n",
       " 'will this work on a pressure cooker',\n",
       " 'can i use this for my 700w electric water urn?',\n",
       " 'will this work on a benq ms504 video projector?',\n",
       " 'when coming to texas for a few months, we forgot our electric cable to our directv receiver box? will this work as a replacement?',\n",
       " 'will this cord work on q vizio tv model number e32ovl 100-2ov-1.5 50/60hz',\n",
       " 'will it work with fender amp',\n",
       " 'can i use this for my percolator?',\n",
       " 'will it work on an electric suzuki piano (same cord but says 120 v 1a) does that mean i have to find a 1a cord or does this 15a cord work fine?',\n",
       " 'i am looking for a replacement power cord for my coby lcd 32\" t.v (tftv3217). will this power cord work?',\n",
       " 'i am looking power cord to be connected to male power adapter hp pavilion entertainment pc',\n",
       " 'how many fast wipes do you receive in this package ????',\n",
       " 'will it help clean the dvd from scratches that makes the movie keep stopping?',\n",
       " 'do they help on dvds they tile when they play in the dvd player?',\n",
       " 'using this drive on windows vista or windows 7: anybody have problems with this?',\n",
       " 'will this product work on a pc with windows xp? and do i not need startup software to make the drive work on my computer?',\n",
       " 'its 2014 now. some of these reviews are older than anything i own! will this zip drive work in windows 8 pc? i just found a bunch of old zip 100',\n",
       " 'can i use this to transfer pc formatted data onto a macbook pro?',\n",
       " 'how do i connect this external zip reader? it has a cable but one is not a usb',\n",
       " \"i'm buying this for someone else...does it come with everything he'll need to plug in and run it?\",\n",
       " 'i have data stored on zip 100 disks. will this device let me download the data from these disks to my desktop?',\n",
       " 'i want to download navigation data and store it on a zip drive. is this the unit i need?',\n",
       " 'mac compatible?',\n",
       " 'external 100 zip drive with plpconnection, is there a cable to use the drive with a cable, plp to usb?',\n",
       " 'does the cord on this item have a flat plug (ie will it fit easily in an outlet that is located behind a sofa) or a straight plug?',\n",
       " 'does this only work on 110v?',\n",
       " 'can the color ring be taken out without the power plugs being loose?',\n",
       " 'does this have a circuit breaker switch (on-off switch)?',\n",
       " 'how many amps is it rated for?',\n",
       " 'can this power strip have holes for mounting it on a vertical surface?',\n",
       " 'does this charger only charge in pairs? is it possible to charge 1 cell (at a time) with this charger?',\n",
       " 'does this charger have individual circuits for each battery, or must they be charged in pairs?',\n",
       " 'out put is 100-240?',\n",
       " 'will this turn off automatically when the batteries are full to prevent overcharging? (energizer universal charger)',\n",
       " 'i need a charger that would charge two of my panasonic 9v batteries at once',\n",
       " 'will these work in a canon rebel t5i camera?',\n",
       " 'can you charge any type of battery such as duracell with this charger?',\n",
       " 'does this plug into a regular outlet to start the charging process?',\n",
       " 'i wanna use in my offroad car 12v, does it come with the cable if not how or where i can buy it?',\n",
       " 'the pictured product is the model chfc2, but the review and other information seems to indicate what is shipped is the chfc. what model is shipped?',\n",
       " 'i have a radio shack md 100 keyboard. will this headphone set fit or do i need an adapter ?',\n",
       " 'are these headphones compatible with the casio keyboard?',\n",
       " 'can i use these in my samsung cell phone?',\n",
       " 'are these headphones compatible with yamaha psre-343 61-key portable keyboard?',\n",
       " 'are these compatible with casio digital piano px150?',\n",
       " 'hi, does this headphone works with casio px 150 digital piano?',\n",
       " 'will these work with casio ca-110 tonebank keyboard?',\n",
       " 'are theses headphones compatible with the yamaha psr320 keyboard?',\n",
       " 'are these headphones compatible with the yamaha p35 piano',\n",
       " 'does the adapter screw on or click in?',\n",
       " 'how do i connect this to usb ?',\n",
       " 'can the trackball be used on windows 7? the old ones would not work.',\n",
       " 'do you use your thumb to move the marble?',\n",
       " \"specifically which usb adapter works? i use trackballs on my macintosh, but can't make this one work.\",\n",
       " \"has anyone successfully converted this to wireless? i'd pay a lot for that!\",\n",
       " 'does this scroll',\n",
       " 'can you scroll with this mouse?',\n",
       " 'is it compatible with the md200tpr?',\n",
       " 'is it compatible with the motorola mr350tpr?',\n",
       " 'can anyone state for sure if the pin is 2.5mm or 3.5mm. thanks',\n",
       " 'do you need a walkie talkie to connect to or is the walkie talkie built in?',\n",
       " 'will these work with the motorola mr350tpr radios?they are talkabouts.!',\n",
       " 'does it plug in to anything?',\n",
       " 'would these work with midland gxt1000vp4 36-mile 50-channel frs/gmrs two-way radio? thanks!',\n",
       " 'do these have a 1 pin or 2 pin connector?',\n",
       " 'does this work with the motorola mh23or walkie talkie (yellow and black)?',\n",
       " 'mr350r',\n",
       " 'does it work with motorola ms355r?',\n",
       " 'can i use this with a 2 pin walkie talkie and only use it for the talking feature?',\n",
       " 'does it work with motorola mt352r frs weatherproof two-way - 35 mile radio?',\n",
       " 'does it work with the mt350r?',\n",
       " 'does this work with the motorola mh360cr talkabout radio?',\n",
       " 'is it water proof?',\n",
       " 'will it work on any motorola walkie talkie with a 3.5mm port?',\n",
       " 'would it work fo galaxy s5',\n",
       " 'can i use this with a uniden bcd396xt scanner as a speaker only?',\n",
       " 'does this work with the motorola ms350r?',\n",
       " 'would i be avaible to record from my pc lap top to my dvd recorder?',\n",
       " 'is this shielded or unshielded?',\n",
       " 'is it good for college student dorms ?',\n",
       " 'has anyone used this particular cable to connect internet phone to modem and if so, any comment on its quality?',\n",
       " 'i have to use ethernet cables to connect to internet. the clips that attach to laptop keep wearing out! are these clips better? will it solve problem?',\n",
       " 'is this cable made of solid or stranded wires',\n",
       " 'can i use this for my xbox and dvd player/',\n",
       " 'will this ethernet cable work with any computer that has a ethernet port?',\n",
       " 'what is the difference between cat5, cat5e and cat6? can this cat5e cable work with signals from a cat6 line?',\n",
       " 'will this cable help me stream youtube videos faster?',\n",
       " 'what is the difference between ethernet and \"network cables\".',\n",
       " 'how difficult is it to disconnect and reconnect this cable? will be using this in a training environment that will be swapped often.',\n",
       " 'is this the swapped/twisted cable or the straight through one? in another word, is this the one used between router and my computer?',\n",
       " 'is this the swapped/twisted cable or the straight through one?',\n",
       " 'do the ethernet cable consist of rj 45 and the length is 3feet?',\n",
       " 'will this work with a verizon htc one android phone?',\n",
       " 'does this come with one earbud or two?',\n",
       " 'does this work with a verizon samsung flip phone',\n",
       " 'what is the ear bud jack size? 2.5 or 3.5mm',\n",
       " 'motorola talkabout earbud with microphone for all series: does this mic work with the t6500 series talkabouts?',\n",
       " 'so will it work with the mh230r?',\n",
       " 'does this have a 2.5 mm or 3.5 mm plug',\n",
       " 'will this work with a i365 two way radio',\n",
       " 'will this work with the cobra cxt 545?',\n",
       " 'will this ear bud work with the motorola 5000 police radio',\n",
       " 'will it play tdk cassettes',\n",
       " 'does this fit 8mm tapes',\n",
       " 'hi i have an old jvc camcorder from 1997 and i need the battery powered vhs-c cassette adapter. the camcorder model is gr-ax820u. will this work?',\n",
       " 'hi there, can i insert a betamax cassette tape in it to play it on a vhs cassette recorder?',\n",
       " 'i have tons of disks with pictures on them. can i use this to move the pictures onto my computer?',\n",
       " 'has anyone used this floppy drive to gain access to an xp floppy disc.--thanks',\n",
       " 'can this device read 720k 3.5 inch diskettes?',\n",
       " 'is this compatible with windows 8???',\n",
       " 'looking at the answered questions, it says the drive is ready to go no additional cable is needed, but reviewers say it does. does it come with the usb cable now?',\n",
       " 'i have a brother wp-3500 word processor that uses floppy disks, i want to know if i can use this on my pc to read these disks and copy them to cd?',\n",
       " 'is this compatible with linux?',\n",
       " 'read 720k',\n",
       " 'can this drive read the iomega100mb zip discs?',\n",
       " 'what is the warranty?',\n",
       " \"i'm trying to get camcorder that will read my older hi 8 cassettes . i've purchased two camcorders that will not read the hi 8 i have . will this one?\",\n",
       " 'can i use my funai recorder to copy my old 8mm tape to dvd using this sony?',\n",
       " 'will this camcorder play fuji super hg double coating 8 taps?',\n",
       " 'is this an xr version?',\n",
       " 'i need to import my old hi 8 tapes to my computer. i have a usb input &amp; firewire - what kind of inputs does this camera support?',\n",
       " 'is this camera ntsc or pal?',\n",
       " 'audio stereo?',\n",
       " 'does it play regular 8mm tapes?',\n",
       " 'does this camera work? does it include all the cables/batteries? manual? can i plug this into the wall instead of using the battery? a/v out inputs?',\n",
       " 'what video cassettes does it use',\n",
       " 'do you know where i can get a tri pod stand for it ?',\n",
       " 'can i use this camcorder to transfer hi8 mp 120 tapes to dvds?',\n",
       " 'does this camcorder come with battery and, if so, what model #?',\n",
       " 'your ad does not mention if this video camera works. does it record and play digital hi-8 video tapes?',\n",
       " 'what kind of out puts does it have ?im looking for the small 4 pin one for your computer.',\n",
       " 'can it be connected directly to a vizio flat-screen tv, without going through a dvd player, which was the case with my old vcr?',\n",
       " 'is it possible to watch one program while taping another?',\n",
       " 'does this unit come with the remote?',\n",
       " 'how old is the unit/',\n",
       " 'can you connect your iphone to hear music from this receiver',\n",
       " 'does it come with remote',\n",
       " 'ab speakers',\n",
       " 'phono input: can you plug in a turntable ?',\n",
       " 'will this work on model pt-70?',\n",
       " 'what length is this tape?',\n",
       " 'will this tape work for a pt-80 model?',\n",
       " 'i have a brother pt-1750 that takes tz tapes. will this work in my labeler?',\n",
       " 'the cartridge in my p-touch has the m-k231s, will the m-k231 advertised here work just as well? what does the \"s\" indicate?',\n",
       " 'what is the length of this tape. i see 5.3 x 3.3 x 0.6 inches mentioned. is it only 5.3 (i assume feet) long?',\n",
       " 'is this tape paper or plastic?',\n",
       " 'will the labels adhere to baggies and mason jars i plan to put in the freezer?',\n",
       " 'will this fit my brother p-touch 2200/2210? thank you!',\n",
       " 'i have a brother p-touch d200 will it fit?',\n",
       " 'so with the adapter, you can plug the radio into something and it will use your car antenna or some other antenna and get further range? how far?',\n",
       " 'are there handle bar mounts for the radio for motorcycle?',\n",
       " 'how far will these radios reach?',\n",
       " 'it is bluetooth compatible?',\n",
       " 'does this have a pa function?',\n",
       " 'made in?',\n",
       " 'is this fm or am',\n",
       " 'do you need a license to operate this radio?',\n",
       " 'does it have a jack for an external speaker ?',\n",
       " 'is anybody else having trouble tuning an external antenna (red line swr readings) connected to the mobile adapter?',\n",
       " 'can this antenna be mounted on a thermalpane rv window?',\n",
       " 'does this antenna have the correct connection to connect to the cobra 75wxst.',\n",
       " 'does this antenna move up, and down so you can tune it to your cb? if not, how do you tune with this one?',\n",
       " 'will the signal transfer thru plastic windshiekd, as in a boat windshield?',\n",
       " 'do you have to use the 12 ft cable that comes with the antenna, or does it work without the wires?',\n",
       " 'how long is the antenna?',\n",
       " 'buy a midland 1001z 40-channel radio, antenna recommend me what to work optimally?',\n",
       " 'will this work on the midland 1001lwx 40 channel mobile cb with weather scan? how far on rang? here is my radio link http://www.amazon.com/midland-1',\n",
       " 'do i need to plug a wire for it to work?',\n",
       " 'how well would this work on a tinted window? and/or would the window tint affect anything?',\n",
       " 'do any of the used scopes come with a tripod?',\n",
       " 'i have a nikon d5000 digital camera can i take pictures with this telescope with proper adapters',\n",
       " 'can you see the rings of saturn',\n",
       " 'can i control the scope with my computer',\n",
       " 'what are you supposed to attach the other end of the cable to???',\n",
       " \"couldn't someone who has bought the same product just use their own key?\",\n",
       " \"i've lost the keys, how can i get a replacement key?\",\n",
       " 'will this work with an mini ipad?',\n",
       " 'will this work for my macbook pro?',\n",
       " 'are the keys all the same? i need 30 for a computer lab &amp; only want to use 1 key.',\n",
       " 'will this work on a dell latitude e6440?',\n",
       " 'will this work with asus rog g751jy?',\n",
       " 'could someone measure the length and width of the t-bar(the small part inserting into slot)? my laptop slot is 5mmx3.5mm, not sure if it can fit',\n",
       " 'what is length of cord?',\n",
       " 'can volume be turned to full off, with no audio coming thru ?',\n",
       " 'does it make it louder than the headphones w/o the volume control, because when i listen to music i want it to be a little bit louder.',\n",
       " 'please explain how this works with an mp3 player. do you plug this into the mp3 player, then plug your headphones into this? can you plug into this??',\n",
       " 'does it work with different types of mp3 players',\n",
       " \"does it work with an ipod to control it's volume as i still use a standard headphone (with no volume control)?\",\n",
       " 'will this work with an iphone headset and a samsung s3?',\n",
       " 'does this koss volume control allow you to set the left and right volume settings independantly to different levels?',\n",
       " 'what size is the connecting jack to the earphones',\n",
       " 'can you skip a song with this or is it only a volume control?',\n",
       " \"how do these compare to the portapro? is sound quality as good or close? i've used the koss clip on. i liked the sound but the clips always came off\",\n",
       " 'do they stay on your head when running or doing housework?',\n",
       " 'how long is the cord length?',\n",
       " 'is there a volume control on these headphones?',\n",
       " \"how do you collapse these to fit into the case? i'm not able to get them in, even after bending in the earpieces.\",\n",
       " 'can the behind-the-head band be removed from the earphones? i use separated phones in a sweat band and find that very',\n",
       " 'is the headband metal or plastic?',\n",
       " 'how well do the foam ear cushions cope with sweat? the ones on my bose headphones are all messed up :-(',\n",
       " 'what are the dimensions of the carrying case?',\n",
       " 'will this plug fit in the 3.5 mm plug ?',\n",
       " 'do these have a mute button inline?',\n",
       " 'will these work with an apple iphone 3g?',\n",
       " 'do these headphones last for a long time?',\n",
       " 'has any one tried to sleep with these in?',\n",
       " 'how is the sound quality??',\n",
       " 'are these inserts memory foam?',\n",
       " 'how long is the cord?',\n",
       " 'is the elaborate tip comfortable expanding foam (like comply tips)? or is it silicone?',\n",
       " 'do you know what the nrr is?',\n",
       " 'are these compatible with the iphone 6?',\n",
       " 'i want to use earphones on a plane, where the noise is very loud and regular headphones are inadequate. will these be better?',\n",
       " 'do these go over the top of your head or around the back? i am looking for something that goes around the back...open to suggestions. thanks!',\n",
       " 'can these receive bluetooth transmissions?',\n",
       " 'can it be used with a tv?',\n",
       " 'are these noise cancelling headphones?',\n",
       " 'noise cancelling',\n",
       " 'are they wireless so i can listen to tv at night while someone is sleeping',\n",
       " 'do these have a noise canceling feature?',\n",
       " 'does this headphone hve a microphone',\n",
       " 'can you use them with your tv',\n",
       " 'can this unit be connected to a 5 channel surround sound system',\n",
       " 'how about a onkyo two channel amp im using for zone 2 on denon avr 990, with two rca plugs, 2 in &amp; 2 out l&amp;r. i have no way to adjust bass and treble',\n",
       " 'im looking for a preamp/equalizer for a turntable i am adding to my home audio system. will this work as a preamp also?',\n",
       " 'can you run fm radio through to alter sound to individual tastes ?',\n",
       " 'odd question - can you mute vocals, leaving only instruments?',\n",
       " 'is ther any warranty of this item eq 200 equalizer',\n",
       " 'can i use this with a ht-rc560 onkyo reciever to record with a phono and cd recorder. thank you.',\n",
       " 'can i use this to record off my phono to my cd recorder. thank you;',\n",
       " 'connecting to a denon avr-3802: can i connect this to a denon avr-3802?',\n",
       " 'would this give you the ability to set up zones? i need to have the ability to turn off/on sound system in certain rooms',\n",
       " 'does this camera take pictures?',\n",
       " 'there is memory card slot',\n",
       " 'does it have automatic film load &amp; reverse or do you have to manually turn and load &amp; reverse?',\n",
       " 'how many mega pixels on this camera?',\n",
       " 'does this product come with batteries and a 35 mm lens?',\n",
       " 'does this come with the film and battery?',\n",
       " 'what type of batteries does this camera need?',\n",
       " \"i'm looking for a camera for a photography class, and my teacher said i need to be able to adjust the f-stop and exposure manually. can i do this?\",\n",
       " 'can i take off the lens of this camera?',\n",
       " 'is this camera fully manual?',\n",
       " 'does it includes guarantee?',\n",
       " 'does it includes guarantee?',\n",
       " 'is it made in japan or made in china? can anyone tell this is made in china or made in japan?',\n",
       " \"replacement headband pad? anyone know if it's possible to buy a replacement headband pad for these headphones?\",\n",
       " 'are these good headphones for audiobook editing',\n",
       " 'iphone',\n",
       " 'will this work in my pc as well as my android phone? also the picture shows the ear configuration without the head band. is that comfortable &amp; secure',\n",
       " \"i know you need an adapter to make it work with an iphone, but once it's connected, does the mute function work with an iphone?\",\n",
       " 'does this fitt the headset plug for a linksys desk phone?',\n",
       " 'with plug-in my computer for use with dragon naturallyspeaking',\n",
       " 'can i use it on both ears?',\n",
       " \"is the head band totally made of plastic? i'm looking for metal, something flexible, that won't snap on a big head\",\n",
       " 'will this work with the clarity c4205 cordless phone?',\n",
       " 'do you have to hold the mute button down to mute or do you click it on/off?',\n",
       " 'can this be used with a desk phone the planatronics t10 and does it plug in with a chord or is it wireless',\n",
       " 'what is voice coil',\n",
       " 'what is the difference between the mdrv6 and the mdr 7506 ?',\n",
       " 'do these headphones have a true, flat sound or do they boost bass/highs/mids/anything? i need headphones for monitoring that reproduce true.',\n",
       " 'do the mdr v6 come with a pouch to keep them in?',\n",
       " 'which country makes it&#xff1f;',\n",
       " \"i love these headphones, however did anyone else receive a pouch that was very smelly (dead fish smell)? not usual chemical smell. hasn't lessened.\",\n",
       " 'can you remove the cord and replace it if needed?',\n",
       " 'is the 10 foot cord a coiled or straight cord',\n",
       " \"i might need to replace my old ones, which seem to be mid-'90s issue - are they still made in japan? anyone aware of other changes since then?\",\n",
       " 'i want to know if there is a volume control on the mdr-v6?',\n",
       " 'odd looking ends. the picture looks like it is male to male. is this really male to female?',\n",
       " 'will this work as extension cord to charge an ipad?',\n",
       " 'is this cable plenum rated for in-wall cable runs?',\n",
       " 'is this extension usable cable of attaining usb 3.0 cable speeds?',\n",
       " 'male to male usb',\n",
       " 'i had to move the printer to another spot, but my usb cords now a little short. will this device work to extend my usb cord?',\n",
       " 'will this power a tp link adaptor for internet?',\n",
       " 'will this plug into the usb end of the logitech webcam and then plug into the usb port on the computer?.',\n",
       " 'can this extend a (1 amp) car charger?',\n",
       " 'can it be used to connect a laptop &amp; move files to an external hard drive (or a portable hard drive) which comes with a short usb cord?',\n",
       " 'hello, i am interested in the sangean sg-622 fm 12 band shortwave world band radio, i live in miami, fl, does this catch central american radios?',\n",
       " 'this device is compatible with \"sangean ant-60 short wave antenna\" , i am going to use the radio in venezuela,do you recommend it?',\n",
       " 'does this radio have the 90 minutes auto shut off to save battery life? thanks',\n",
       " 'what model ac adapter is compatible for this radio?',\n",
       " 'does this model have an external antenna jack? i ask because the \\'frequently bought together\" offer is the radio and an external antenna.',\n",
       " 'does this radio have fm, am and ssb?',\n",
       " 'does this radio come in the color that is shown in the picture',\n",
       " 'hello, do you have this radio available in the grayish black color as shown on the image?',\n",
       " 'what is the frequency range on short wave for the sg-622w',\n",
       " 'one reviewer hung the antenna from his 2nd-story balcony. is reception better using the antenna vertically or horizontally? does it matter?',\n",
       " 'will this antenna improve the am reception of my grundig s450dlx sw radio?',\n",
       " \"i'm new at this game. so my question is--- how do you attach this ant to your radio?//thanks\",\n",
       " \"what's the performance with 20 up to 40 meters bands?\",\n",
       " 'does it work on a grundig s350dl ?',\n",
       " 'will this antenna work with grundig yb 305 model ?',\n",
       " 'i have a grundig s450dlx sw radio and wanted a antenna for it. will it connect to a 75 ohm coax connector in back?',\n",
       " 'how long is this antenna and can you use it in door',\n",
       " 'has anybody hooked two of these together and if so, how well does it work?',\n",
       " 'will this also improve am reception?',\n",
       " 'ps3 compatible???? can anyone tell me if this hard drive will work on a ps3??',\n",
       " 'could you show me the firmware?? thank you.',\n",
       " 'i need exact specifications disk. model st3500320as and firmware: sd1a. is to exchange with one broken plate.',\n",
       " 'does this drive really have a 5 year warranty?',\n",
       " 'ps3 compatible???? can anyone tell me if this hard drive will work on a ps3???',\n",
       " 'is the firmware sd15 ?',\n",
       " 'harddisk for t61? is this hdd compatible with t61?',\n",
       " 'my wireless router wired ports are all used up. will this switch allow me to expand the number of ports while keeping my wireless router going?',\n",
       " 'does it matter which port i put in the ethernet cord providing the internet?',\n",
       " 'just to clarify, does this device plug into the wall?',\n",
       " 'does the device have slots in the bottom for wall-mounting?',\n",
       " 'i need two data drops about 50ft from my current switch. i already have one data drop in that room can i use this two make that one data drop three?',\n",
       " 'lets say you plug in three ethernet cords,would it make the connection slower',\n",
       " \"cat5 or cat6 cables with router? or doesn't matter?\",\n",
       " 'how can i use a fixed ip address behind this. when i put the switch in, i lose the internet.',\n",
       " 'i have this switch, cable modem, airport express, roku 3, ethernet-ready tv, do i still need a router to hard wire roku to tv?',\n",
       " 'can i run this from a router hooked to a cable modem?',\n",
       " 'will it work with led bulb?',\n",
       " 'can activate a relay ? i have led light 12v . i was thinking to connect a relay and use the contact . does it works ?',\n",
       " 'is there an on/off switch on the sensor?',\n",
       " 'does this come as pictured with the mounting stub or is it just the sensor? thanks.',\n",
       " 'is this sensor will work decorative lights for out side the garage door .can 2 lights work with 1 sensor?',\n",
       " 'will it fit a different co light all-pro mst27920les, 270 degree motion twin led floodlight, energy star, bronze',\n",
       " \"does anyone know if you can hear a relay actuating? if so, that's why it works a with 120v led.\",\n",
       " 'what is the maximum detection range?',\n",
       " 'will it work with cfl bulbs?',\n",
       " 'will this unit work in parallel with (2) 3 way 120 vac light switches. how will i know you know what you are talking about when you answer.',\n",
       " 'dose the plastic tape stick better to plastic kitchen container. i used the paper type and it lifts off after a short time. (day or two!)',\n",
       " 'can i peel the tape off cleanly and easily if i wish to remove the label?',\n",
       " 'wich on is better for fabrics?',\n",
       " 'does the plastic tape hold up outdoors? want to use on plant id stakes.',\n",
       " 'is the tape white and it prints black letters, numbers etc ??',\n",
       " 'there are 2 tapes in each cartridge, do they both contain 13 feet each of tape = a total of 26 feet, or together, do they equal 13 feet? thank you kindly',\n",
       " 'how do i correct printing on only half the tape with a dymo lectratag 100h?',\n",
       " 'i want to label daylilies. will this work outdoors?',\n",
       " 'will this refill fit the dymo letratag qx50? the cartridge says 91331 12mm on it.',\n",
       " 'is this waterproof or water resistant?',\n",
       " 'would this work with connecting a xbox 360: i was wondering if this product would make i possible for me to connect my xbox 360 and my cable internet to the same computer and use them both at once?',\n",
       " 'hub or switch for wirless bridge: should i get a hub or a switch to connect to the wireless bridge to be able to do so?',\n",
       " 'is this unit a wired unit? i do not want any wireless equipment. i need to run two computers, will this work for me ? thank you.',\n",
       " 'is the power supply for this unit 100/220 50/60hz ??',\n",
       " \"xbox 360: i don't know much on networks so what would be the best choice for connecting 3 or 4 360s, a hub or switch and which brand?\",\n",
       " 'modem only has 1 ethernet output. if not what exactly is this thing?',\n",
       " 'are zip drives only useful for reading and transferring data off of old zip media?',\n",
       " 'will it work with mac osx 10? thanks.',\n",
       " \"how do i back up all my files as i need to change from window's xp to window's 7/\",\n",
       " 'is it windows 8 compatible?',\n",
       " 'do surge protectors actually work, or do they just give a false sense of security? has anyone had their equipment saved from a lightening strike?',\n",
       " \"does this version not have a phone line protection? the decsription doesn't say, but the graph below says it does. which is it?\",\n",
       " 'is there any insurance against equipment damage that comes with this model',\n",
       " 'is it 120v only,or 120-240v?',\n",
       " 'how many joules does this surge protector have?',\n",
       " 'is this digital',\n",
       " 'how long is the cord?',\n",
       " 'can this be mounted on a wall',\n",
       " 'can we add the monster power surge to an extension cord? my computer and other items is far away from the wall outlet.',\n",
       " 'if all the cords from tv are pluged into it and the red switch is off dose it still work?when there is a lighting storm?',\n",
       " 'bluray plug? anyone know of a similar device that has bluray support?',\n",
       " 'new smart tv being installed next week. is this appropriate for this job. it is a samsung',\n",
       " 'is this product can plug into 220v and will it protect the equibment 110v? i travel oversea alot and i need adapter convert to my 110 volt equibment',\n",
       " 'is this good for geocaching? can i put in coordinates and get accurate and close results?',\n",
       " 'can i return to my starting destination anywhere without additional maps',\n",
       " 'can it be charged up from an electricity outlet (as in the car)? if not, which hiking gps models have that capacity?',\n",
       " \"is there a gps service i'd have to purchase to get this to work?\",\n",
       " 'can you use alternate storage',\n",
       " 'usb charger?',\n",
       " 'does it tell you the elevation? if so how close is it?',\n",
       " 'how about using this guy for hunting adventures?',\n",
       " 'how waterproof is the etrex',\n",
       " 'is this mac comparable',\n",
       " 'is there a warrenty on the mailbug? how long? what does it cover?',\n",
       " 'do i understand correctly that there is no spam control with this unit? with the former mail staton that my mil had, it was really necessary',\n",
       " 'does it send and receive overseas email, eg from germany?',\n",
       " 'is there a local landel \"hook-up\" phone number for temecula, ca?',\n",
       " 'when the machine is on and running, does it disable your phone? or can both be used at the same time.',\n",
       " 'if a person buys one off of amazon versus the landel site, does the buyer still get to pick an email address?',\n",
       " 'can it be used with wi fi. do you have to use their e mail service',\n",
       " 'can you change the font size on the mailbug for a very near-sighted older lady?',\n",
       " 'what is the monthly subscription rate?',\n",
       " 'what is the monthly subscription rates?',\n",
       " 'does it have a calendar with an alarm',\n",
       " 'does this come with a doc, the manual and the cd to load the program?',\n",
       " 'is palmone iiixe compatible with windows 7 64-bit',\n",
       " 'this this device have a calendar function?',\n",
       " 'does the organizer have an alarm',\n",
       " 'does a polaroid spectra system se camera use this polaroid spectra film twin pack?',\n",
       " \"what types of film can polaroid 600 cameras use? can polaroid 600's use any other film besides polaroid 600 film?\",\n",
       " 'does it still work even though it is out dated by many years?/',\n",
       " 'what is the expiration date of this film you have left?',\n",
       " 'so if i were to buy this camera all i would need to get is film? and which film? and then it will work fine?',\n",
       " 'can it take 300 pack film?',\n",
       " 'if the camera is discontinued is the film still going to be available',\n",
       " 'does it come with the film?',\n",
       " 'is there a cheaper one?',\n",
       " 'do you have to use the impossible film with the impossible frog tongue?',\n",
       " 'what size are the photos and is the film from this website compitable- http://shop.the-impossible-project.co...',\n",
       " 'have you tested it camera already ?',\n",
       " 'is there a flash? what makes it so much cheaper than the other (non \"600\") instant camera?',\n",
       " 'where do you buy the film?',\n",
       " 'would like to try this flash with a nikon d70s. would i be able to bounce the flash off a high ceiling?',\n",
       " \"vivitar 283 help: i have the pdf manual - but it doesn't say anything about it, any switches or something i missed?\",\n",
       " 'is this 283 one of the newer, low trigger voltage ones, or the original high-voltage model?',\n",
       " 'is this flash compatible with a pentax k1000? thanks.',\n",
       " 'hi there. does your vivitar 283 flash come with a pcsync cord to use with a nikon s2 rangefinder that has a cold shoe?',\n",
       " 'is this flash compatible with pentax asahi k1000?',\n",
       " 'nikon fm10 compatibility?',\n",
       " 'is this camera adjustable for both aperature and shutter speed',\n",
       " 'does camera use a disk or film????',\n",
       " \"how many mp's?\",\n",
       " 'what size battery are used',\n",
       " 'what is the warranty on this used 8mm camcorder?',\n",
       " 'do all of the cables, connections and battery come with this camera?',\n",
       " 'does it play old 8 mm tapes?',\n",
       " 'could someone give me a step-by-step instruction on how to connect the camcorder to a tv? thanks.',\n",
       " 'can i use this camera to import video into final cut?',\n",
       " 'can this camcorder connect to a television so you are able to view them on a bigger screen?',\n",
       " 'i can not view through the finder or see a tape.',\n",
       " 'sony ccd-trv37 camcorder: will the sony ccdtrv57 8mm camcorder work with my old tapes?',\n",
       " 'how close will they focus?',\n",
       " 'can i use them to watch in the night?',\n",
       " 'does it come with a neck strap',\n",
       " 'can it be mounted on tripod',\n",
       " 'country of origin',\n",
       " \"some people have said these binoculars are tripod mountable (with an adapter) and others say they aren't. if they are, what kind of adapter is needed?\",\n",
       " 'is there a case and strap that comes with this as well?',\n",
       " 'where it is made from?',\n",
       " \"i'm looking for binos for a concert, i'm in the nose bleed section looking staight at the stage the fartest distance from the stage which ones be best\",\n",
       " 'multicoated : 7 layesrs multicoating or 2 layers multicoating...pls help?',\n",
       " 'i plan to use these for the symphony. what is the best magnification and how do they function in dim lighting?',\n",
       " 'can you use these with prescription eyeglasses?',\n",
       " 'my husband and i enjoy the ocean and just wondering if any of you that have bought these have used these for different ships, etc?. thanks much',\n",
       " 'the product states it is \"compact\" but the description states the dimensions are 3x4x7, this hardly appears to be \"compact\". what is the actual size?',\n",
       " 'which binocular is best for bird watching?',\n",
       " \"why can't you seperate out the reviews by the sub-product line. 8x21 is a lot different than 12x32 for example. i cant' tell what they are reviewing\",\n",
       " \"i am going to see a broadway show but i'm kind of far back on the balcony. how would they do in the lighting changes of the show?\",\n",
       " 'what is the weight of th 12 x 25? are they heavy for travel? we want them for our cruise. would they be good for using from the balcony of the ship?',\n",
       " 'are these good for watching wildlife',\n",
       " 'going on a european river cruise - what size would work for views from the riverboat?',\n",
       " 'i plan to use these for the symphony. what is the best magnification and how do they function in dim lighting?',\n",
       " 'can you use these with prescription eyeglasses?',\n",
       " 'my husband and i enjoy the ocean and just wondering if any of you that have bought these have used these for different ships, etc?. thanks much',\n",
       " 'the product states it is \"compact\" but the description states the dimensions are 3x4x7, this hardly appears to be \"compact\". what is the actual size?',\n",
       " 'which binocular is best for bird watching?',\n",
       " \"why can't you seperate out the reviews by the sub-product line. 8x21 is a lot different than 12x32 for example. i cant' tell what they are reviewing\",\n",
       " \"i am going to see a broadway show but i'm kind of far back on the balcony. how would they do in the lighting changes of the show?\",\n",
       " 'what is the weight of th 12 x 25? are they heavy for travel? we want them for our cruise. would they be good for using from the balcony of the ship?',\n",
       " 'are these good for watching wildlife',\n",
       " 'going on a european river cruise - what size would work for views from the riverboat?',\n",
       " 'is this router compatible with motorola surfboard sb6141 docsis 3.0 modem ?',\n",
       " 'i used this circa 2008 with cox modem,vista laptop, roku box, specifically to watch netflix. will it still work with newer fast speeds &amp; new roku box?',\n",
       " 'router question: what is this called specifically or what should i be looking for specifically?',\n",
       " 'where manufactured?',\n",
       " \"i'm having trouble setting it up with two macbooks running os x, and an arris cm820a docsis 3.0. it doesn't seem i can use the cd to install software?\",\n",
       " 'is this a good choice for streaming netflix, etc.?',\n",
       " 'can this router do \"dhcp reservation\" via the connected elements\\' mac addresses?',\n",
       " 'is this compatible with centurylink?',\n",
       " 'is this a good choice for a roku 3.i will need to tun 40 feet of cat 6',\n",
       " 'has this product been discontinued?',\n",
       " 'what is the expiration date on the kadak 200 film?',\n",
       " 'what is the expiration date on kodak 200 print film',\n",
       " 'is this 35mm?',\n",
       " 'expiration date for kadak gold 200 print four pack film',\n",
       " 'where can i get it developed?',\n",
       " 'is this multi plug or just one outlet at the end of the extension cord:',\n",
       " 'can this extension cord be used with a portable generator to run from the generator into the house to plug in regular ext cord to use household items?',\n",
       " \"i don't know much about extension chords and all, but to be clear.. this is safe for outdoors even when it rains??\",\n",
       " \"can i use this as my power cord for an electric weed-eater? can't find my cord that came with it!\",\n",
       " \"can a portion of this be buried under a few inches of ground? i don't want to unplug my bug zapper every time i mow.\",\n",
       " \"i want to buy it for my ipod or iphone?but i don't know which adapter i need to buy together? who can give me some advice? thanks a lot!\",\n",
       " 'i am in college and dont want to disturb my roomate. will the leakage be too loud? if so is a pair of the sennheiser hd dj headphones same or better',\n",
       " 'sound leakage',\n",
       " \"are those 'over the ear' or 'around the ear' headphones?\",\n",
       " 'just received my new hd600.both channels cutting out. have to wiggle the cables all the time. is this a known or common problem?',\n",
       " 'can my emotiva xda-2 and fiio e7 able to power this can? are there better dacs &amp; amps that i can buy to help?',\n",
       " 'will (an amp) + schiit modi dac make a significant difference over just using an amp? (assuming all my cds and files are lossless quality)',\n",
       " 'bass response?',\n",
       " 'what is the original purchase date of the headphones and estimated hours of use?',\n",
       " \"dose hd600 have the case of sound leakage? who have campared this one to the pxc450.i want to know wether hd600's sound is good than pxc450? but dose hd 600 have the function of noise cancelling?\",\n",
       " 'is it ac/dc',\n",
       " 'i am looking for something to play my old cassettes on. will this work for that?',\n",
       " 'does this play old cassette tapes?',\n",
       " 'does it come with wall plug-in or adapter?',\n",
       " 'can i use this to make mixtapes (will it connect to a cd player/cassette player)?',\n",
       " \"i need this product to play my tapes. does it have good understanding voice replay. does it have electric cord as i don't want one that uses only batt\",\n",
       " 'can you use headphones or earbuds to listen to cassettes on this recorder/player?',\n",
       " '2 months shoe box recorders were 24 dollars now almost 70 why',\n",
       " 'does it have a clear sound and no background noise that comes from the inside of the player., like so many of these do?',\n",
       " 'what type or brand of plug in microphone works best on this tape deck?',\n",
       " 'stereo? is this thing supposed to be in stereo on the headphones?',\n",
       " 'is the antenna a direct pull up or does it require a twisting motion when lowering to lock in place?',\n",
       " 'do the batteries last a good while with this radio?',\n",
       " 'i want it mainly for am stations..is sound good for that',\n",
       " 'can i plug it in rather than rely on batteries alone?',\n",
       " 'will this radio stand upright on a table or night stand??',\n",
       " 'does it come with ear plug?',\n",
       " 'is it smaller than the sony?',\n",
       " 'can u use these with an ipad?',\n",
       " \"could this fit a child's head? 4 year old?\",\n",
       " 'will this work with my kindle fire?',\n",
       " 'will these work well outside brisk walk or running with an ipod?',\n",
       " 'can i purchase 30?',\n",
       " 'i just want my husband to wear them to bed so i can sleep!!!! will these help drown out the sound of my tv????',\n",
       " 'does this have volume control',\n",
       " 'do they fit kids?',\n",
       " 'would you say the bass is too dominate in that it drowns out the mids and highs?',\n",
       " 'will this headphone jack fit through the headphone jack on my iphone 5s life proof case?',\n",
       " 'what are the dimensions and actual weight?',\n",
       " 'what are the best binoculars for bird watching with in the range of from 20ft to 100yds?',\n",
       " 'can you focus one eye separately in the event you have better vision in one eye vs the other?',\n",
       " 'have you tried these to look at stars ? wondering how these would work for astronomical purposes.',\n",
       " 'weight?',\n",
       " 'what are the measurements of this binocular by inches?',\n",
       " 'does it come with a strap and carrying case?',\n",
       " 'would these work for someone with a small head? i noticed they came up when i searched \"kids binoculars.\" mose adult sized ones are too big!',\n",
       " 'are these binoculars recommended for theater use?',\n",
       " \"do they work well for concerts or the opera on let's say the third balcony?\",\n",
       " 'can this lens be used with canon rebel t3?',\n",
       " 'will this lens work with a cannon 7d mark i?',\n",
       " 'can this lens be used with a canon eos 550d?',\n",
       " 'will this lens work on a canon eos rebel xs? thanks!',\n",
       " 'is this lens for digital cameras?',\n",
       " 'does this lens auto focus and will it auto focus on my 50d',\n",
       " 'does this ship to puerto rico?',\n",
       " 'is this compatible with the canon t3i camera',\n",
       " 'is this compatable w/ a canon eos rebel xti?',\n",
       " 'will this lense work with a canon eos elan iie camera?',\n",
       " 'will it fit eos 10d?',\n",
       " 'will it fit the new eos sl1?',\n",
       " 'will ithis fit a 7d',\n",
       " 'will this fit a 60d ?',\n",
       " 'does this have a lens cap and back cap?',\n",
       " 'will this fit on a canon eos digital rebel xt?',\n",
       " 'will this lens work on a cannon rebel t3',\n",
       " 'this would be a gift, dose it fit a rebel eos t3i?',\n",
       " 'will this lens work on the canon eos elan ii',\n",
       " 'will work with t1i',\n",
       " 'is this flash canon 550ex compatible with canon 5d mk11',\n",
       " 'does this work with canon rebel t2i',\n",
       " 'does this work with the canon 6d?',\n",
       " 'is this compatible to 60d?',\n",
       " 'will this flash be compatible with eos rebel t4i',\n",
       " 'cannon eos rebel t2i: would that one fit my camera and do you think it would be good for what i need?',\n",
       " 'i just bought a canon eos rebel t3i and it has a 18-55mm lens........will the ef 75-300 work with this camera and to what end....',\n",
       " 'does this lens work with eos 6d camera? can i see the full frame pictures?',\n",
       " 'what is the difference between usm and non- usm?',\n",
       " 'what is the non usm verses usm???? im learning ....',\n",
       " 'will my canon xs510hr work with a 75 300 lens',\n",
       " 'usm vs non usm. whats the difference',\n",
       " 'what is the difference between the canon ef 75-300mm f/4-5.6 iii and the older model ef 75-300mm f/4-5.6 ii?',\n",
       " 'hey i have a t4i canon camera. can i use this lens on this camera. also i mostly shoot videos with my camera. can i use this lens on this camera for v',\n",
       " 'would this work with the sl1? (a.k.a 100d)',\n",
       " 'what is weight? what is diamentions ( h x w x l ? )',\n",
       " 'where can i find replacement eye cups for my 18x50 canon is binoculars',\n",
       " 'does anyone make isbs with digital outputs that can capture images to a laptop or smartphone?',\n",
       " 'do you need to hold the is button down continuously on these newer models? specifically the 18x50',\n",
       " 'what size threaded filter is applicable for the canon 15x50 is binocular objectives? it seems to be 58mm; is that correct?',\n",
       " 'are these 18x50 or 15x50 ? please make it clear in your product heading.',\n",
       " 'the fujinons have an excellent adjustable eye relief; rotate click stop. so nice.. i am assuming the canons do not have a feature like this?',\n",
       " 'has anyone found rain guards &amp; objective covers that fit the canon 15x50 is binocs? if so please provide the brand and who to buy from. thanks!',\n",
       " 'how much do they weigh',\n",
       " 'thanks to all for the answer to my previous question. do these come with a threaded fitting that allows attachment to a standard tripod or monopod?',\n",
       " 'does this lens have vibration control?',\n",
       " 'is this lens compatable with a canon rebel xt dslr?',\n",
       " 'will this lense work well with a cannon t3i?',\n",
       " 'what is the overall length of the lens?',\n",
       " 'can this be used on a cannon eos rebel 2000',\n",
       " 'will this work with a canon eos rebel t3i',\n",
       " 'will this fit the canon eos rebel t3?',\n",
       " 'does this lens work with the cannon eos rebel g?',\n",
       " 'can you use on digital canon cameras?',\n",
       " 'can i use this lens with my canon slr digital camera with 12 mp?',\n",
       " 'on the section to order its asking me styler non usm or usm. what does this mean?',\n",
       " 'which lens for a canon rebel t3i would be the best for filming surfers from the shore ?',\n",
       " 'is this lens only for digital slrs or for film slrs cameras? is this lens only for digital slrs or for film slrs cameras?',\n",
       " 'does the lens have image stabilizer?',\n",
       " 'lenses for canon eos rebel xt ?? could someone tell me or point me to a website that shows what lenses go with a digital eos rebel xt ?',\n",
       " 'will this lens work with the canon rebel t5i?',\n",
       " 'what is the screw on filter size for this lens?',\n",
       " 'will this lens work with a canon eos rebel k2?',\n",
       " 'there are 2 versions of this lens: usm and non-usm. i understand that usm is better, why is the us version $40 cheaper than non-usm?',\n",
       " 'anyone use it for kids sporting events (soccer &amp; basketball)? how do you like it?',\n",
       " 'do you have to program it',\n",
       " 'can you use rechargable batteries and recharge it while in the radio?',\n",
       " 'is a seperate antenna required?',\n",
       " \"i bought one in 2007. now i can't find the charging adapter or the mobile charger. where can i buy replacements?\",\n",
       " 'made in?',\n",
       " 'i\\'m buying as a gift... will this work for this station: \"freq: 460.07500 type: rm tone:151.4 pl?\"',\n",
       " 'can you use this to listen to ems/police/fire?',\n",
       " 'how does it hold up in weather?',\n",
       " 'does this come with the ac charging adapter?',\n",
       " 'does this radio work well with a stock cb/radio antenna on the jeep, do i have to wire it to anything or will it pick up a signal wireless?',\n",
       " 'can these flash units be used with modern digital cameras without damaging the electronics of the cameras. i heard this is problem with older designs',\n",
       " 'is this for nikon or canon?',\n",
       " 'could someone explain the comment, \"older flashes can damage digital cameras.\" i have a vivitar 283 or 383 and want to use it with a panasonic fz70',\n",
       " 'is it sold with a sync pc cord? does it works well on a mamiya 7 ii, without frying anything? thanks, best regards',\n",
       " 'has it been tested and works with nikon d1x?',\n",
       " 'shalli use this 285hv flash for nikon d7100',\n",
       " 'can this flash be used with a pocket wizard plus ii transceiver?',\n",
       " 'will this cnnect to and work with a canon sx50 hs? if not, why?',\n",
       " 'will this flash work with a leica m8 with a nikon sc 28 cable?',\n",
       " 'will this flash work with the panasonic lumix dmc-g3?',\n",
       " 'where can i get the film developed?',\n",
       " 'how old is the film being sold?',\n",
       " \"i have an aps kodak camera i need the film.it sells on amazon but what's the expired date of the film before its no good any more.how old is the film\",\n",
       " 'good evening...what are the exact expiration dates for the fuji 800 film...thank you',\n",
       " 'mailman left it in my black mailbox, on a super hot day, for a couple of hours. anyone happen to know how resilient the film is to heat?',\n",
       " 'why are you charging shipping on each pack of these on bulk orders, instead of one solid price for them all?',\n",
       " 'excuse me, are those films expired? or can you tell me its due date?',\n",
       " 'what is the expiration date of your fuji 35mm iso 200 film?',\n",
       " 'should i use 200 or 400 speed for rainy days',\n",
       " 'is this color print film',\n",
       " 'what is the difference between fuji super hq 200 and fuji film 200 ?',\n",
       " 'does it have a microphone jack?',\n",
       " 'does this item have a \"line out\" jack ? besides the headphone/mic jacks.',\n",
       " \"my cd's are not being recognized\",\n",
       " 'what is the total peak power output capability of the unit/speakers?',\n",
       " 'do they have a warranty?',\n",
       " 'description-watts per channel,will my kindle fire connect',\n",
       " 'how many mhz is the phillips fr 965?',\n",
       " 'what kind of wire connections',\n",
       " 'will this work on kl-60?',\n",
       " 'will this tape work for the kl-7200?',\n",
       " 'is this tape for a kl-780?',\n",
       " 'why are you showing a double pack for the price and when you order it you get the price doubled? also i have prime and it charged me shipping!',\n",
       " 'does it have a cable provided?',\n",
       " \"can't tell. does it include the remote?\",\n",
       " 'can you set a timer and record a show on a analog tv',\n",
       " 'does the sony slv-n50 stereo vcr - slvn50 work on a digital t.v. or must the t.v. be an analog? can i record from the tv to this vcr?',\n",
       " 'does this unit have a tuner?',\n",
       " 'will this play on modern tv. i understand it will not record in hd, but will it record from qam tuner tv? also will it record from cable box?',\n",
       " 'does it come with remote',\n",
       " 'does it come with a remote, and if not where do i get one to use with this machine',\n",
       " 'can you record from this unit',\n",
       " 'i have a tc-we605s and need a manual. can anyone help? should be that different from a 305s.',\n",
       " 'if you are going to replace it, what model should you buy?',\n",
       " 'can this duplicate tapes?',\n",
       " 'does it work with modern sony stereo receivers?',\n",
       " 'are speakers built in in the unit?',\n",
       " \"does this include the piece that screws into the gps? mine broke and i can't remember whether that was part of the original gps or came with my mount\",\n",
       " 'will it support the etrex 20?',\n",
       " 'will it fit 1.5 inch handlebar?',\n",
       " 'will it fit 1\" handlebars ?',\n",
       " 'does it suit to garmin etrex 30?',\n",
       " ...]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<314263x69189 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2033712 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokeniza perguntas e converte dados para o formato de matriz\n",
    "# e treina o modelo CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_vec = vectorizer.fit_transform(questions)\n",
    "X_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<314263x69189 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2033712 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforma dados aplicando \"term frequency inverse document frequency\" (TF-IDF) \n",
    "tfidf = TfidfTransformer() # aplica normalização \"l2\" por defaul\n",
    "X_tfidf = tfidf.fit_transform(X_vec)\n",
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversation(im):\n",
    "    global tfidf, answers, X_tfidf\n",
    "    Y_vec = vectorizer.transform(im) # cria a matriz com as  quantidades de cada palavra do dicionário\n",
    "    Y_tfidf = tfidf.fit_transform(Y_vec) # aplica o TF-IDF na matriz\n",
    "    cos_sim = np.rad2deg(np.arccos(max(cosine_similarity(Y_tfidf, X_tfidf)[0]))) # calcula o cos e retorna o maior\n",
    "    if cos_sim > 60 :\n",
    "        return \"sorry, I did not quite understand that\"\n",
    "    else:\n",
    "        return answers[np.argmax(cosine_similarity(Y_tfidf, X_tfidf)[0])]\n",
    "\n",
    "def main():\n",
    "    usr = input(\"Please enter your username: \")\n",
    "    print(\"support: Hi, welcome to Q&A support. How can I help you?\")\n",
    "    while True:\n",
    "        im = input(\"{}: \".format(usr))\n",
    "        print(im)\n",
    "        if im.lower() == 'bye':\n",
    "            print(\"Q&A support: bye!\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Q&A support: \"+conversation([im]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "support: Hi, welcome to Q&A support. How can I help you?\n",
      "battery life of my phone\n",
      "Q&A support: so far after i charge the battery it will last about 90 minutes. i have not had any issues with the battery.\n",
      "?\n",
      "Q&A support: sorry, I did not quite understand that\n",
      "Does it have bluetooth\n",
      "Q&A support: no\n",
      "theft?\n",
      "Q&A support: have to see if it covers it.\n",
      "bye\n",
      "Q&A support: bye!\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
