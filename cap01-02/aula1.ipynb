{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hands On - Aula01.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **PLN: Processamento de Linguagem Natural**\n",
        "## ***(NLP: Natural Language Processing)***"
      ],
      "metadata": {
        "id": "3ZBkm5VtkBNA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **O que é NLP?**\n",
        "\n",
        "#### Definição informal:\n",
        "\n",
        "- ##### *Instruir o computador a \"ler e escrever\", ou seja, a lidar com a língua*\n",
        "\n",
        "#### Definição formal da Comissão Especial de NLP da Sociedade Brasileira de Computação:\n",
        "\n",
        "- ##### *A área de Processamento da Linguagem Natural (PLN), também denominada Linguística Computacional ou, ainda, Processamento de Línguas Naturais, lida com problemas relacionados à **automação da interpretação e da geração da língua humana** em aplicações como Tradução Automática, Sumarização Automática de Textos, Ferramentas de Auxílio à Escrita, Perguntas e Respostas, Categorização Textual, Recuperação e Extração de Informação, entre muitas outras, além das tarefas relacionadas de criação e disponibilização de dicionários/léxicos e córpus eletrônicos, desenvolvimento de taxonomias e ontologias, investigações em linguística de córpus, desenvolvimento de esquemas de marcação e anotação de conhecimento linguísticocomputacional, resolução anafórica, análise morfossintática automática, análise semântico-discursiva automática, etc*<br><br>\n",
        "\n",
        "#### **Por que é tão desafiador?**\n",
        "\n",
        "#### Resumidamente, a diferença mais importante entre a linguagem computacional e as linguagens naturais é a **ambiguidade**. Linguagens de programação formais são projetadas para serem inequívocas, enquanto humanos lidam naturalmente com:\n",
        "\n",
        "- ##### Irregularidade\n",
        "- ##### Vagueza\n",
        "- ##### Variedade\n",
        "- ##### Sarcamo\n",
        "- ##### Sinônimos\n",
        "- ##### Dupla negação\n",
        "- ##### Expressões retóricas, etc...\n",
        "<br>\n",
        "\n",
        "#### **Campo de pesquisa interdisciplinar**:\n",
        "\n",
        "- ##### Computação\n",
        "- ##### Matemática\n",
        "- ##### Linguística\n",
        "- ##### Neurociência\n",
        "<br>\n",
        "\n",
        "#### **Exemplos de aplicações**:\n",
        "\n",
        "- ##### Assistentes virtuais e chatbots\n",
        "- ##### Tradução automática\n",
        "- ##### Revisão ortográfica e gramatical\n",
        "- ##### Análise de sentimentos\n",
        "- ##### Extração e recuperação de dados não estruturados\n",
        "- ##### Sumarização de textos\n",
        "- ##### Classificação e indexação\n",
        "- ##### Jurimetria"
      ],
      "metadata": {
        "id": "FIdm1GyulIJs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conceitos básicos**"
      ],
      "metadata": {
        "id": "1cBp5XrjiOJ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Atomização (*tokenization*)**\n",
        "#### Dividir um documento de texto em uma lista de unidades de sentido (palavras, símbolos, frases...)\n"
      ],
      "metadata": {
        "id": "Nhpo8i5Jyafd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download()"
      ],
      "metadata": {
        "id": "Iet4JPn_ylQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Repare, por exemplo, que o nltk.word_tokenize() trata os pontos diferentemente do método .split()\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = \"We are studying NLP. Who would have thought that computer programs would be analyzing human sentiments?\"\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3J3ayuezcbu",
        "outputId": "0b113821-ba43-4d1f-dbab-4ee3627f61b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['We', 'are', 'studying', 'NLP', '.', 'Who', 'would', 'have', 'thought', 'that', 'computer', 'programs', 'would', 'be', 'analyzing', 'human', 'sentiments', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note que é possível também dividir o documento em sentenças, e não apenas em palavras\n",
        "\n",
        "sentences = nltk.tokenize.sent_tokenize(text)\n",
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeKi6-jTK5NS",
        "outputId": "cecc6071-d7f1-4991-9ad2-11e4a5b6dbca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['We are studying NLP.',\n",
              " 'Who would have thought that computer programs would be analyzing human sentiments?']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Neste exemplo, veja como o NTLK consegue separar bem as frases mesmo com o ponto na expressão \"Mr.\"\n",
        "\n",
        "text2 = \"Hello, Mr. John Smith. You are late.\"\n",
        "\n",
        "sentences = nltk.tokenize.sent_tokenize(text2)\n",
        "\n",
        "print(sentences[0])\n",
        "print(sentences[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyupoQCh0BSv",
        "outputId": "dc575d74-9fbb-4cb9-cd36-53b8a8110656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, Mr. John Smith.\n",
            "You are late.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Palavras vazias (*stopwords*)**\n",
        "#### Em geral, conectores com baixa relevância semântica (artigos, pronomes, preposições, conjunções verbos auxiliares...)\n",
        "#### Obs: Podemos adicionar/remover termos da lista, a depender do caso."
      ],
      "metadata": {
        "id": "Ik3ng4-o4E2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vazias = nltk.corpus.stopwords.words('portuguese')\n",
        "print(vazias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06XsKLXk0BDB",
        "outputId": "6048fcb9-8192-424b-a0cd-02a3ff656973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['de', 'a', 'o', 'que', 'e', 'é', 'do', 'da', 'em', 'um', 'para', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'ao', 'ele', 'das', 'à', 'seu', 'sua', 'ou', 'quando', 'muito', 'nos', 'já', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'depois', 'sem', 'mesmo', 'aos', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'você', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'numa', 'pelos', 'elas', 'qual', 'nós', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "print(stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_LGor9m7KiS",
        "outputId": "4f877abe-d4de-4418-f8a8-7f7259d35397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_sw = [word for word in tokens if word not in stopwords]\n",
        "\n",
        "print(tokens_sw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKtvHmm37rBN",
        "outputId": "42131c58-9eb5-472f-b98c-7bf319fd37b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['We', 'studying', 'NLP', '.', 'Who', 'would', 'thought', 'computer', 'programs', 'would', 'analyzing', 'human', 'sentiments', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Neste exemplo, note que foram subtraídas as palavras 'are', 'have', 'that' e 'be'. Relembre a frase original:\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHF1VTZVt7J7",
        "outputId": "1117437e-b084-493b-843d-5cf90bcb7adf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['We', 'are', 'studying', 'NLP', '.', 'Who', 'would', 'have', 'thought', 'that', 'computer', 'programs', 'would', 'be', 'analyzing', 'human', 'sentiments', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Radiciação (*stemming*)**\n",
        "#### Reduz variações de uma palavra a um um radical.\n",
        "#### Ex: estudando, estudioso, estudei → estud"
      ],
      "metadata": {
        "id": "fhN7WhgZ8zRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "text = \"We are studying NLP. Who would have thought that computer programs would be analyzing human sentiments?\"\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "tokens_st = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "print(tokens_st)\n",
        "\n",
        "# Neste exemplo, foram reduzidas as palavras 'studying' (studi), 'computer' (comput), 'programs' (program), 'analyzing'(analyz) e 'sentiments' (sentiment)\n",
        "# Repare que nem todas dentre as novas versões são palavras existentes na língua"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmWnlGyU7B8A",
        "outputId": "3aa64306-4177-4ed0-d7a3-9dc89f9a6976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['We', 'are', 'studi', 'nlp', '.', 'who', 'would', 'have', 'thought', 'that', 'comput', 'program', 'would', 'be', 'analyz', 'human', 'sentiment', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Lematização (*lemmatization*)**\n",
        "#### Reduz variações de uma mesma palavra à sua forma canônica, levando em conta sua classe gramatical.\n",
        "#### Ex: estudando, estudioso, estudei → estudar"
      ],
      "metadata": {
        "id": "fxidEe7--FtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "text = \"We are studying NLP. Who would have thought that computer programs would be analyzing human sentiments?\"\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "tokens=[lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "print(tokens)\n",
        "\n",
        "# Neste exemplo, foram reduzidas apenas as palavras 'programs' (program) e 'sentiments' (sentiment) para sua versão no singular\n",
        "# Repare que essas são palavras existentes na língua"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xf1B2X1p7BxA",
        "outputId": "a10edcab-e07b-4014-877c-f93a95d0b6ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['We', 'are', 'studying', 'NLP', '.', 'Who', 'would', 'have', 'thought', 'that', 'computer', 'program', 'would', 'be', 'analyzing', 'human', 'sentiment', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Etiquetagem de classes gramaticais (*Part of speech tagging* ou *POS tagging*)**\n",
        "#### Relaciona uma palavra a sua provável classe gramatical."
      ],
      "metadata": {
        "id": "9g5J2sLNNbDN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **OBS:** Exemplo de implementação baseada em estrutura de Árvore de Análise Sintática (Linguística/Gramática Universal)"
      ],
      "metadata": {
        "id": "xOz8mxUU24yy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![ch07-tree-1.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAcIAAAChCAMAAABj0U83AAAJJmlDQ1BpY2MAAEiJlZVnUJNZF8fv8zzphUASQodQQ5EqJYCUEFoo0quoQOidUEVsiLgCK4qINEWQRQEXXJUia0UUC4uCAhZ0gywCyrpxFVFBWXDfGZ33HT+8/5l7z2/+c+bec8/5cAEgiINlwct7YlK6wNvJjhkYFMwE3yiMn5bC8fR0A9/VuxEArcR7ut/P+a4IEZFp/OW4uLxy+SmCdACg7GXWzEpPWeGjy0wPj//CZ1dYsFzgMt9Y4eh/eexLzr8s+pLj681dfhUKABwp+hsO/4b/c++KVDiC9NioyGymT3JUelaYIJKZttIJHpfL9BQkR8UmRH5T8P+V/B2lR2anr0RucsomQWx0TDrzfw41MjA0BF9n8cbrS48hRv9/z2dFX73kegDYcwAg+7564ZUAdO4CQPrRV09tua+UfAA67vAzBJn/eqiVDQ0IgALoQAYoAlWgCXSBETADlsAWOAAX4AF8QRDYAPggBiQCAcgCuWAHKABFYB84CKpALWgATaAVnAad4Dy4Aq6D2+AuGAaPgRBMgpdABN6BBQiCsBAZokEykBKkDulARhAbsoYcIDfIGwqCQqFoKAnKgHKhnVARVApVQXVQE/QLdA66At2EBqGH0Dg0A/0NfYQRmATTYQVYA9aH2TAHdoV94fVwNJwK58D58F64Aq6HT8Id8BX4NjwMC+GX8BwCECLCQJQRXYSNcBEPJBiJQgTIVqQQKUfqkVakG+lD7iFCZBb5gMKgaCgmShdliXJG+aH4qFTUVlQxqgp1AtWB6kXdQ42jRKjPaDJaHq2DtkDz0IHoaHQWugBdjm5Et6OvoYfRk+h3GAyGgWFhzDDOmCBMHGYzphhzGNOGuYwZxExg5rBYrAxWB2uF9cCGYdOxBdhK7EnsJewQdhL7HkfEKeGMcI64YFwSLg9XjmvGXcQN4aZwC3hxvDreAu+Bj8BvwpfgG/Dd+Dv4SfwCQYLAIlgRfAlxhB2ECkIr4RphjPCGSCSqEM2JXsRY4nZiBfEU8QZxnPiBRCVpk7ikEFIGaS/pOOky6SHpDZlM1iDbkoPJ6eS95CbyVfJT8nsxmpieGE8sQmybWLVYh9iQ2CsKnqJO4VA2UHIo5ZQzlDuUWXG8uIY4VzxMfKt4tfg58VHxOQmahKGEh0SiRLFEs8RNiWkqlqpBdaBGUPOpx6hXqRM0hKZK49L4tJ20Bto12iQdQ2fRefQ4ehH9Z/oAXSRJlTSW9JfMlqyWvCApZCAMDQaPkcAoYZxmjDA+SilIcaQipfZItUoNSc1Ly0nbSkdKF0q3SQ9Lf5RhyjjIxMvsl+mUeSKLktWW9ZLNkj0ie012Vo4uZynHlyuUOy33SB6W15b3lt8sf0y+X35OQVHBSSFFoVLhqsKsIkPRVjFOsUzxouKMEk3JWilWqUzpktILpiSTw0xgVjB7mSJleWVn5QzlOuUB5QUVloqfSp5Km8oTVYIqWzVKtUy1R1WkpqTmrpar1qL2SB2vzlaPUT+k3qc+r8HSCNDYrdGpMc2SZvFYOawW1pgmWdNGM1WzXvO+FkaLrRWvdVjrrjasbaIdo12tfUcH1jHVidU5rDO4Cr3KfFXSqvpVo7okXY5upm6L7rgeQ89NL0+vU++Vvpp+sP5+/T79zwYmBgkGDQaPDamGLoZ5ht2GfxtpG/GNqo3uryavdly9bXXX6tfGOsaRxkeMH5jQTNxNdpv0mHwyNTMVmLaazpipmYWa1ZiNsulsT3Yx+4Y52tzOfJv5efMPFqYW6RanLf6y1LWMt2y2nF7DWhO5pmHNhJWKVZhVnZXQmmkdan3UWmijbBNmU2/zzFbVNsK20XaKo8WJ45zkvLIzsBPYtdvNcy24W7iX7RF7J/tC+wEHqoOfQ5XDU0cVx2jHFkeRk4nTZqfLzmhnV+f9zqM8BR6f18QTuZi5bHHpdSW5+rhWuT5z03YTuHW7w+4u7gfcx9aqr01a2+kBPHgeBzyeeLI8Uz1/9cJ4eXpVez33NvTO9e7zofls9Gn2eedr51vi+9hP0y/Dr8ef4h/i3+Q/H2AfUBogDNQP3BJ4O0g2KDaoKxgb7B/cGDy3zmHdwXWTISYhBSEj61nrs9ff3CC7IWHDhY2UjWEbz4SiQwNCm0MXwzzC6sPmwnnhNeEiPpd/iP8ywjaiLGIm0iqyNHIqyiqqNGo62ir6QPRMjE1MecxsLDe2KvZ1nHNcbdx8vEf88filhICEtkRcYmjiuSRqUnxSb7JicnbyYIpOSkGKMNUi9WCqSOAqaEyD0tandaXTlz/F/gzNjF0Z45nWmdWZ77P8s85kS2QnZfdv0t60Z9NUjmPOT5tRm/mbe3KVc3fkjm/hbKnbCm0N39qzTXVb/rbJ7U7bT+wg7Ijf8VueQV5p3tudATu78xXyt+dP7HLa1VIgViAoGN1tubv2B9QPsT8M7Fm9p3LP58KIwltFBkXlRYvF/OJbPxr+WPHj0t6ovQMlpiVH9mH2Je0b2W+z/0SpRGlO6cQB9wMdZcyywrK3BzcevFluXF57iHAo45Cwwq2iq1Ktcl/lYlVM1XC1XXVbjXzNnpr5wxGHh47YHmmtVagtqv14NPbogzqnuo56jfryY5hjmceeN/g39P3E/qmpUbaxqPHT8aTjwhPeJ3qbzJqamuWbS1rgloyWmZMhJ+/+bP9zV6tua10bo63oFDiVcerFL6G/jJx2Pd1zhn2m9az62Zp2WnthB9SxqUPUGdMp7ArqGjzncq6n27K7/Ve9X4+fVz5ffUHyQslFwsX8i0uXci7NXU65PHsl+spEz8aex1cDr97v9eoduOZ67cZ1x+tX+zh9l25Y3Th/0+LmuVvsW523TW939Jv0t/9m8lv7gOlAxx2zO113ze92D64ZvDhkM3Tlnv296/d5928Prx0eHPEbeTAaMip8EPFg+mHCw9ePMh8tPN4+hh4rfCL+pPyp/NP637V+bxOaCi+M24/3P/N59niCP/Hyj7Q/Fifzn5Ofl08pTTVNG02fn3Gcufti3YvJlykvF2YL/pT4s+aV5quzf9n+1S8KFE2+Frxe+rv4jcyb42+N3/bMec49fZf4bmG+8L3M+xMf2B/6PgZ8nFrIWsQuVnzS+tT92fXz2FLi0tI/QiyQvpNzTVQAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAMxQTFRF////AECAAECAAECAAECAAECAAECAAECAAECAAECAAECAAECAAECAAECAAGBgAGBgAGBgAGBgAGBgAGBgAGBgAGBgAGFhAGBgAGBgAGBgAGBgAGBgAGBgAGBgAGBgAGBgAGBgAGBgAGBgAGBgAGBgAGFhAGBgAECAAGBgAGBgAGBgAGBgAGBgAGBgAGBgAGBgAGFhAGFhAIBAAIBAAIBAAIBAAIBAAIBAAIBAAIBAAIBAAIBAAIBAAIBAAIBAAIBAAECAAGBgAIBA////5JREcAAAAEB0Uk5TAEQzEZnuiLvMIneq3WZEd4iqu/f2zI9VMxHxImbdmWDW+u/ZrZfuVfLD0Pn1z7/Ea0BEiLtVme7dEcxmM3ciqka/HW4AAAABYktHRACIBR1IAAAACXBIWXMAAABkAAAAZAAPlsXdAAAAB3RJTUUH4wQCBR8FuHaVPQAADcFJREFUeNrtnWmDqjoShrH7tL0eRWccdUTnzuaZ7c4itAsuDfz/HzWVhYAIJgHZPPV86KaVhKReU6lEqDYMBEEQBEEQ5P7odB7qbgJSgMdvHvDUrbsdSG6ePe/l+cnzUMO28up5b/Dr3fuouyVITjqe9wq/Xrs4CtsKjMKPt07drUCK0CXRjPfSfay7IUhuHrrPVETUsNU8vHve97obgeSjw+MYXFW0lg5bVDzgKGwvLySWgbX9B86FbeWRBjPeM26TtpjXTqfzWncjEARBEARBkJ+UXq9vDoa/+e3od+NJ3W1BdJj2xqY5HPqM3/Pfo4GJQjadWc8C6UZcsvlwYVq9mdH3/2D94vt//BMK2Vwm4C8XwzmXbjg0zXFvKt4d+HA8M+HtP//lr/wsEBLERWqn1zNhqlsy5ZZEul7v8ix/yM9ewJkDy4ChyoWEYYpC1sL5VDcfDsx+L9s39nxTFLSg0HJBz0Uh64BMdQsx1Y34VCfD9OMjc9YH3eb9sBh4YD6KUcgymdClQdZUJ2O0TFZHHOrQimqYxoXsa1SNyCBTnfCXS/CXqVOdhKk/uHzRGhCHOj4/UQi5HJooZCHYVBdfGlyb6mSM/X7qRfpwgbl54TpRyCKwqW4upjpTaaqTYfpZ8k9MkGpkpak060FLfBRSFbYLtoxNdb0bGm0+v/LmeAFXHIwz3j0T0tL34XfP9GKq6+eY6mTM/MX1VljgUJfmFUcdCTlHIRmzi6nOKjDVybB8S9ogsnEz6l/32UTI0c8u5ORiqhtXsBBb+CrXCDdupH0Ym4OfUMi0qa66qy9HaufFN25kRELe9575+S7YUrILVhaTaHdNCtu4MVU9w/0Kmf6FT130/bHO6RcbN/ISYzP68qPlQl7/wqcu6BdNWqRt3EiJ9syJkG3bamVLA9kXPnURftGkQ9bGjdwU7fryQ+8Ln7roaUyFca5s3Miv2RYhTa0vfOrCWub2CGTjRr7KyCTcah3kr6Jseo2Y6kplmm8Uxmvo9Rs0qSAIgiAIYpCkA0/keeeu59HkZoT3Jj0+++Z59HnsJ68btu+F5A1ix0/fVB/WpskV4p29Hzt5LHFEvGmNeoj9kWVF6Hjeg2gfHGq3lUsYdfZ+7MQtwpv2zFrZpFQS79432qiXsH2vZEDy4zflzCWhhKKz92OnJ++JNCjWtIYldPnuPRkky8WbaN8zEZUff6PvKkA7Fe/s/dgJ2vHh/Yg37ZHldWkK0JwOSZ33Str30ul0uuSF0Iw/WFpEpX6ed/Z+7ARN+wFOnTfto9vtvqhapSLewfjfiR8Vc9B3Q0jYoXqq9fO8s/djJ49Get2zaboZ/iGEyPdOP/DP3tPz8/OH9/SQX0LR2fuxE2nIAwTnrGnERO8/6m7TOeCwmB8NZaP5gPnxd11HKjp7P3ai4R3N8CnM0jTevWfqR8P2vcXa+k01vTMPZ6LO3o+daNcen5rYtBAYaSxw4IuKFzEKydSkt6iIOns/dmI2eGti00LAkzJvKZb2P6Jj1byykYS8s/djJ/4xfmlg0wTvvF3hBtsPcfyhnN05JiHr7B3aCUEQBEEQpOVMFgu8NUuFWfPurTXIHZKDv7GbSE2rkQ2MMTQLFJ4MC9xHylj4Oe9FLo3p2OT3b//9H/4//0XvWG70IwR57scX5L0VXDAd+L/8KnnKuEpmFnvK9d+/gm7gRcdL/z//ZYrOB2ZD3WqtEk5H/mAKP0ZNuGV60h/MqVT9/5lLf870gs/Ysk/eY9KOFv3mudVCEs6KSThZsgG48Ef1GmbaYyNttLBm5BkFfx5NEDAQh8yL9kyqcePcaiEJjUISgnG4pUx/WZuGs7E54sJQXzCe+0sz7hX4QBRnU7GX4Fab4DoI9Ulo+ctxdFzkAZvcgH+cUz3Egx09EMhMahMNRF7MYqrPF414IKQ2CRdnI6+3rDow7bHnquaL2KJhNvD9RYqTPBuIYfl+6Fatmt1qQQnzlgajnMcwk1F1gWm4bAh9Z/jygoWhaSQHYlTRkuVNGtfnVuuRkIaiFy9VEZhOLOY7h8klwjQKQ1NbnDIQGTMrXHXU5FZrkTAMRc+Ylh6Ygu9jvjNlZXAehqaRPhBF1fSTUctmTh0SRqHoOSUGpqHvHKUvCC7C0NQ6Mgcifx9WHcsaVh3FJBzmKR0PRZPvlBGYhlsuw6x1QGoYmsbVgcgvNq58M6d6CRdXxtrNA9NoyyXzmllhaBqygSiuWuVmTtUSXoSiic7PbxaYnm+5ZJ51JQxNQ2EgcirbzCko4VKzQEooenHCDQLT5JZL5tWuh6GpRdQGomhH+Zs5BSX09c5PDUUTJioamF5uuWQiD0PTUB+IvEElb+ZUKmFWKHpOgcA0bcsluzUqYWgaWgMxbFl5mzlVSpgdiibPyxGYZmy5ZKIchqahOxCjJpawmVNMwoWOhAvl0aUbmGZuuWSiE4amkWcg8ivffDOnmISmuoSSUPQcrcDUzNxyycTSC0PTgIGYP/WY2My5xZqjMgmHklD0HBK5KjdipB22zzTD0NQm6ubzTJYnmzm3mBeLJWecqVtibOp10GzeHQ4IgiAI0ihiKcfEs66eSsEou0OePA8XteSoJJ69TCMJWrDSeX2Vdbo2mpZW710s7Vf7JIyyl2kkQStNQtu5+rampdV7l0g5ppptpSESiuxlGknQ6pNQy9LqvUukHGuThPHsZRpJ0ILP9Wa73sGR7QYuObD3+82KSnhw9qCaE7g2OdPebtafcgl5NXC2c7hymqal1XuXSDnWJgnj2cs0kqAFG+doBy6YPrD39mZtGI67sU9EwgP56zP4gvfhYB3Yx6+NVMKwmr2zhVqy0bS0eu8S+apaJqHIXqaRBC0g/m4ffBobMtSI93M2ZEwGK6qgsSU/jsHhEBzhwJFKKKpRcqTKllbvXbslFNnLNJKgBXvykxreME4OkXBNXz9uNoaY/AIYiURYBUcaVnNzCRV7l0g5piRhp9vlNo+O9BFl81YSz16mkQSNaQI2P63dINgSCamcQQAukUjIsO2AvCoPZ0Q1ahKqWlq9d4mUY0oSUnMnfugjyuatJJ69TCMJGrhQwLV3G/fzwBwpk/AI09oJNOMTmqKEUTVqEqpaWr13iZRjqhI+CsM/FpDwMZQwVyXx7GUaSdDIUDNOwZ6JE5NwZexgMJ2oxCfnwFyoLZMwqkZFQnVLq/cukXJMzZHC+hTKvceP9BFl81YSz16mkQQtIFq5mx0NVz43bkxCmPn2ENwc4P0txDUujElpRBpVo7i0V7S0eu8SKcfUwpmuaEo31ihdRNmclcSzl2kkQQvWMNOBTLBocLfuGpYPkYQkON05/P3DBg720rlQVHMM3OvrQi1L5+ydMq+dzkPyqEAtRSrJwWm1IsGmcViBPKtLs9PXgd1qdVKoTlTDq0UQBEEQBEHyMdG/n3B6k//Mm+PCpbSjKrRbq3x/o+6jOcYNEo/lvXCSpuWfu4q21ZTvMkYJKyKHhIrDECWsiEZJOG2MhA3+j/AXNErC23z6byFhoSdaKgYlTG3HXUtolSrhLXIyoITSAmVKeAvT3UDCOUpIaLOEuVIv1UUOCRWft0cJKyKHhIoFWi3h6AbtqIpmSXiTT/8tJCxeRXWghCVVUR0oYUlVVIf+tmSpEt7CdCihjJ9BQo2kL/WDEqZx7xIqzlcoYUU0S0Kt3HG3vHAC029RgqRmSXiTT/9NJGzCv5tRpDwJzRwLBOsWi4o8F75oR4tGof5/qxyYdbcZQRAEQRoPe0RSCfKUc2AnXsjPRXV63C5BWkVoWFqd6FlzJYi9nT17Jpn+QAkVodYqJGHWg+A5JAxrQwl1KE1CmjjMsY9u8EUfWBb5xzJgo5CWYjnHaKoWSaGQ4xe95DoqISTcOwFJf7a2w35+ySoUCdJ4UVK/u7EPjtFImLUiS8tttncDh+ZXkeR4o4nDnK3zud9sjVj+sSyYzWkplnMMXpAWCvkMDiRPyzEqEUoIf+zXcGBvaO4emlTkel0iQVpYlCVDc9ygVqWyBaHWEpaW24z05ot8RKU53qgj3e5IVjIjyj+WWTG3+ZkjlRYSkKxZ++AUleDV7bgEOyIyfOg+4azrmQdEgjRRFD4bcLTbNlRC7khDS0ttxvrlfinkeBNz4SqI5R/LrDlFQnkhwRo+f19O7DK8uhXtC0naA685NniYtSsxSJggLSrK0jbZzZaQW1puM/YZPnGNr+Z4S0jI849l1pwqoayQAAbZDjxkVCKsLggr//oygpXtGltJbSK7VlSUHbVFQpnNon5Ic7wlJJTlWUmVUCU5C2NzPMKnKyrBq/tkbhM+lPtgRdzpSuaWhYRR0WOrJJTZTPRDnuPtTEKRfyyz5hQJ5YUi1q67jl+GV3egL5CJ8BQ4LswDzlZSkUiQFhVlR1+tkFBuM+ZqYT6R53g7kzDKP5ZFWjgjLRRvGG27KBFGpM72ZJxcMv+55E9XHt+KBGmxou4ORnErJFSw2RZ6c9jYCjneSOKwSEKRfywLbnOaboz+IPGkrFC8YbTVokQo4QHcfbAlVdhEY5slnLyGSJAWFT1s4WDdVAmptYSl5TYjvQmcnUqOt0TisDD/mARaShRVLASEYcpFiZVyFZwoQZooCi/tbFevmurQNvSKp4drVo63T5XVY052dDdgq7DFgOTH2ZS5/WUHa3u7UQ+PkRzYx1I9wcou+QIIgiAIgiAIgkT8H75hib36ksSGAAAAJXRFWHRkYXRlOmNyZWF0ZQAyMDE5LTA0LTAxVDIwOjMxOjA1KzA5OjAwK2wowwAAACV0RVh0ZGF0ZTptb2RpZnkAMjAxOS0wNC0wMVQyMDozMTowNSswOTowMFoxkH8AAAAidEVYdHBzOkhpUmVzQm91bmRpbmdCb3gAMzI0eDExNi0xNjEtNTclgbOoAAAAHHRFWHRwczpMZXZlbABBZG9iZS0zLjAgRVBTRi0zLjAKm3C74wAAACJ0RVh0cHM6U3BvdENvbG9yLTAAZm9udCBIZWx2ZXRpY2EtQm9sZLVGv7UAAAAASUVORK5CYII=)"
      ],
      "metadata": {
        "id": "hxp2DqXGzAH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"We are studying NLP. Who would have thought that computer programs would be analyzing human sentiments?\"\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "classes = nltk.pos_tag(tokens)\n",
        "classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ7S9_9r7Bt1",
        "outputId": "98941151-58bb-4285-f7db-5accd31bb7ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('We', 'PRP'),\n",
              " ('are', 'VBP'),\n",
              " ('studying', 'VBG'),\n",
              " ('NLP', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Who', 'WP'),\n",
              " ('would', 'MD'),\n",
              " ('have', 'VB'),\n",
              " ('thought', 'VBN'),\n",
              " ('that', 'IN'),\n",
              " ('computer', 'NN'),\n",
              " ('programs', 'NNS'),\n",
              " ('would', 'MD'),\n",
              " ('be', 'VB'),\n",
              " ('analyzing', 'VBG'),\n",
              " ('human', 'JJ'),\n",
              " ('sentiments', 'NNS'),\n",
              " ('?', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Na biblioteca NLTK, lista de etiquetas está disponível em:\n",
        "nltk.help.upenn_tagset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaOJKMmk3SWk",
        "outputId": "450c3506-edba-45a3-bcbb-dfa2bce3db2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$: dollar\n",
            "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
            "'': closing quotation mark\n",
            "    ' ''\n",
            "(: opening parenthesis\n",
            "    ( [ {\n",
            "): closing parenthesis\n",
            "    ) ] }\n",
            ",: comma\n",
            "    ,\n",
            "--: dash\n",
            "    --\n",
            ".: sentence terminator\n",
            "    . ! ?\n",
            ":: colon or ellipsis\n",
            "    : ; ...\n",
            "CC: conjunction, coordinating\n",
            "    & 'n and both but either et for less minus neither nor or plus so\n",
            "    therefore times v. versus vs. whether yet\n",
            "CD: numeral, cardinal\n",
            "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
            "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
            "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
            "DT: determiner\n",
            "    all an another any both del each either every half la many much nary\n",
            "    neither no some such that the them these this those\n",
            "EX: existential there\n",
            "    there\n",
            "FW: foreign word\n",
            "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
            "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
            "    terram fiche oui corporis ...\n",
            "IN: preposition or conjunction, subordinating\n",
            "    astride among uppon whether out inside pro despite on by throughout\n",
            "    below within for towards near behind atop around if like until below\n",
            "    next into if beside ...\n",
            "JJ: adjective or numeral, ordinal\n",
            "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
            "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
            "    multilingual multi-disciplinary ...\n",
            "JJR: adjective, comparative\n",
            "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
            "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
            "    cozier creamier crunchier cuter ...\n",
            "JJS: adjective, superlative\n",
            "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
            "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
            "    dearest deepest densest dinkiest ...\n",
            "LS: list item marker\n",
            "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
            "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
            "    two\n",
            "MD: modal auxiliary\n",
            "    can cannot could couldn't dare may might must need ought shall should\n",
            "    shouldn't will would\n",
            "NN: noun, common, singular or mass\n",
            "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
            "    investment slide humour falloff slick wind hyena override subhumanity\n",
            "    machinist ...\n",
            "NNP: noun, proper, singular\n",
            "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
            "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
            "    Shannon A.K.C. Meltex Liverpool ...\n",
            "NNPS: noun, proper, plural\n",
            "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
            "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
            "    Apache Apaches Apocrypha ...\n",
            "NNS: noun, common, plural\n",
            "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
            "    divestitures storehouses designs clubs fragrances averages\n",
            "    subjectivists apprehensions muses factory-jobs ...\n",
            "PDT: pre-determiner\n",
            "    all both half many quite such sure this\n",
            "POS: genitive marker\n",
            "    ' 's\n",
            "PRP: pronoun, personal\n",
            "    hers herself him himself hisself it itself me myself one oneself ours\n",
            "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
            "PRP$: pronoun, possessive\n",
            "    her his mine my our ours their thy your\n",
            "RB: adverb\n",
            "    occasionally unabatingly maddeningly adventurously professedly\n",
            "    stirringly prominently technologically magisterially predominately\n",
            "    swiftly fiscally pitilessly ...\n",
            "RBR: adverb, comparative\n",
            "    further gloomier grander graver greater grimmer harder harsher\n",
            "    healthier heavier higher however larger later leaner lengthier less-\n",
            "    perfectly lesser lonelier longer louder lower more ...\n",
            "RBS: adverb, superlative\n",
            "    best biggest bluntest earliest farthest first furthest hardest\n",
            "    heartiest highest largest least less most nearest second tightest worst\n",
            "RP: particle\n",
            "    aboard about across along apart around aside at away back before behind\n",
            "    by crop down ever fast for forth from go high i.e. in into just later\n",
            "    low more off on open out over per pie raising start teeth that through\n",
            "    under unto up up-pp upon whole with you\n",
            "SYM: symbol\n",
            "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
            "TO: \"to\" as preposition or infinitive marker\n",
            "    to\n",
            "UH: interjection\n",
            "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
            "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
            "    man baby diddle hush sonuvabitch ...\n",
            "VB: verb, base form\n",
            "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
            "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
            "    boost brace break bring broil brush build ...\n",
            "VBD: verb, past tense\n",
            "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
            "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
            "    speculated wore appreciated contemplated ...\n",
            "VBG: verb, present participle or gerund\n",
            "    telegraphing stirring focusing angering judging stalling lactating\n",
            "    hankerin' alleging veering capping approaching traveling besieging\n",
            "    encrypting interrupting erasing wincing ...\n",
            "VBN: verb, past participle\n",
            "    multihulled dilapidated aerosolized chaired languished panelized used\n",
            "    experimented flourished imitated reunifed factored condensed sheared\n",
            "    unsettled primed dubbed desired ...\n",
            "VBP: verb, present tense, not 3rd person singular\n",
            "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
            "    appear tend stray glisten obtain comprise detest tease attract\n",
            "    emphasize mold postpone sever return wag ...\n",
            "VBZ: verb, present tense, 3rd person singular\n",
            "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
            "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
            "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
            "WDT: WH-determiner\n",
            "    that what whatever which whichever\n",
            "WP: WH-pronoun\n",
            "    that what whatever whatsoever which who whom whosoever\n",
            "WP$: WH-pronoun, possessive\n",
            "    whose\n",
            "WRB: Wh-adverb\n",
            "    how however whence whenever where whereby whereever wherein whereof why\n",
            "``: opening quotation mark\n",
            "    ` ``\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Reconhecimento de Entidades Nomeadas (*Named-entity recognition*)**\n",
        "#### Localizar e classificar entidades como pessoas, organizações, locais...\n",
        "\n",
        "Tipos no NLTK:\n",
        "- ORGANIZATION\n",
        "- PERSON\n",
        "- LOCATION\n",
        "- DATE\n",
        "- TIME\n",
        "- MONEY\n",
        "- PERCENT\n",
        "- FACILITY\n",
        "- GPE\t(geo-political entities)\n"
      ],
      "metadata": {
        "id": "MVXhbLuWP0kv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text4 = '''\n",
        "The Washington Monument is the most prominent structure in Washington D.C., and one of the city's early attractions.\n",
        "It was built in honor of George Washington, who led the country to independence and then became its first President.\n",
        "'''\n",
        "\n",
        "tokens4 = word_tokenize(text4)\n",
        "classes4 = nltk.pos_tag(tokens4)\n",
        "\n",
        "entidades = nltk.chunk.ne_chunk(classes4)\n",
        "print(entidades)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRuJMSgqQnB_",
        "outputId": "5b3b5b80-d7d8-458a-d1d9-32dd665999f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  The/DT\n",
            "  (ORGANIZATION Washington/NNP Monument/NNP)\n",
            "  is/VBZ\n",
            "  the/DT\n",
            "  most/RBS\n",
            "  prominent/JJ\n",
            "  structure/NN\n",
            "  in/IN\n",
            "  (GPE Washington/NNP D.C./NNP)\n",
            "  ,/,\n",
            "  and/CC\n",
            "  one/CD\n",
            "  of/IN\n",
            "  the/DT\n",
            "  city/NN\n",
            "  's/POS\n",
            "  early/JJ\n",
            "  attractions/NNS\n",
            "  ./.\n",
            "  It/PRP\n",
            "  was/VBD\n",
            "  built/VBN\n",
            "  in/IN\n",
            "  honor/NN\n",
            "  of/IN\n",
            "  (PERSON George/NNP Washington/NNP)\n",
            "  ,/,\n",
            "  who/WP\n",
            "  led/VBD\n",
            "  the/DT\n",
            "  country/NN\n",
            "  to/TO\n",
            "  independence/VB\n",
            "  and/CC\n",
            "  then/RB\n",
            "  became/VBD\n",
            "  its/PRP$\n",
            "  first/JJ\n",
            "  President/NNP\n",
            "  ./.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **N-gramas**\n",
        "#### Sequência contígua de *n* itens de uma amostra de texto. Muito útil para a desambiguação (abordagem estatística).\n",
        "#### **Ex:** *Sue swallowed the large green ________ (tree, frog, mountain, car, pill)*"
      ],
      "metadata": {
        "id": "1HL7CJL9UR3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import bigrams\n",
        "from nltk import trigrams\n",
        "from nltk import ngrams"
      ],
      "metadata": {
        "id": "s69VRmjQVCMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"We are studying NLP. Who would have thought that computer programs would be analyzing human sentiments?\"\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "list(bigrams(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLDsuNj_VO_W",
        "outputId": "2fa49e6b-c64e-402a-a234-ff4e648b721f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('We', 'are'),\n",
              " ('are', 'studying'),\n",
              " ('studying', 'NLP'),\n",
              " ('NLP', '.'),\n",
              " ('.', 'Who'),\n",
              " ('Who', 'would'),\n",
              " ('would', 'have'),\n",
              " ('have', 'thought'),\n",
              " ('thought', 'that'),\n",
              " ('that', 'computer'),\n",
              " ('computer', 'programs'),\n",
              " ('programs', 'would'),\n",
              " ('would', 'be'),\n",
              " ('be', 'analyzing'),\n",
              " ('analyzing', 'human'),\n",
              " ('human', 'sentiments'),\n",
              " ('sentiments', '?')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(trigrams(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtUpOEj3VXXx",
        "outputId": "cc657cc6-67f6-4876-9edf-c5350150dabb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('We', 'are', 'studying'),\n",
              " ('are', 'studying', 'NLP'),\n",
              " ('studying', 'NLP', '.'),\n",
              " ('NLP', '.', 'Who'),\n",
              " ('.', 'Who', 'would'),\n",
              " ('Who', 'would', 'have'),\n",
              " ('would', 'have', 'thought'),\n",
              " ('have', 'thought', 'that'),\n",
              " ('thought', 'that', 'computer'),\n",
              " ('that', 'computer', 'programs'),\n",
              " ('computer', 'programs', 'would'),\n",
              " ('programs', 'would', 'be'),\n",
              " ('would', 'be', 'analyzing'),\n",
              " ('be', 'analyzing', 'human'),\n",
              " ('analyzing', 'human', 'sentiments'),\n",
              " ('human', 'sentiments', '?')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(ngrams(tokens,4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o15ru83gVbaJ",
        "outputId": "5d7425f0-cc0e-463c-eae1-27d374303a7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('We', 'are', 'studying', 'NLP'),\n",
              " ('are', 'studying', 'NLP', '.'),\n",
              " ('studying', 'NLP', '.', 'Who'),\n",
              " ('NLP', '.', 'Who', 'would'),\n",
              " ('.', 'Who', 'would', 'have'),\n",
              " ('Who', 'would', 'have', 'thought'),\n",
              " ('would', 'have', 'thought', 'that'),\n",
              " ('have', 'thought', 'that', 'computer'),\n",
              " ('thought', 'that', 'computer', 'programs'),\n",
              " ('that', 'computer', 'programs', 'would'),\n",
              " ('computer', 'programs', 'would', 'be'),\n",
              " ('programs', 'would', 'be', 'analyzing'),\n",
              " ('would', 'be', 'analyzing', 'human'),\n",
              " ('be', 'analyzing', 'human', 'sentiments'),\n",
              " ('analyzing', 'human', 'sentiments', '?')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Vetorização**\n",
        "#### Representação de um texto na forma de um vetor para permitir operações de álgebra linear."
      ],
      "metadata": {
        "id": "6XA5lJPpwYUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install scikit-learn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "text3 = [\"How to change payment method and payment frequency\"]\n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "vectorizer.fit_transform(text3).todense()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLH8nMgJi07M",
        "outputId": "c1734833-fef3-4bc2-d6a0-4000736ff03b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[1, 1, 1, 2]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ánalise de Sentimentos**\n",
        "\n"
      ],
      "metadata": {
        "id": "YxJ70eG3_te7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exemplo com a biblioteca **`TextBlob`**:\n",
        "##### Como avaliar o resultado:\n",
        "- ##### A pontuação de polaridade varia de -1 a 1, do sentimento mais negativo ao mais positivo;<br> \n",
        "- ##### A pontuação de subjetividade varia de 0 a 1, do mais objetivo ao mais subjetivo."
      ],
      "metadata": {
        "id": "yvL47HSBCHaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install TextBlob\n",
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "2bAgZt9w-Ear"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TextBlob(\"I love pizza\").sentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-sEsswN-EJz",
        "outputId": "9efa807c-4084-42e8-ab22-af470e75d86f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment(polarity=0.5, subjectivity=0.6)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TextBlob(\"The weather is excellent\").sentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ianiUbHi-EG8",
        "outputId": "0f1959ab-0a07-4d78-8777-352e7924576f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment(polarity=1.0, subjectivity=1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TextBlob(\"What a terrible thing to say\").sentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqbQK03a-EC0",
        "outputId": "371891ce-12e1-414c-c8a3-2c6590ad85a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment(polarity=-1.0, subjectivity=1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exemplo com a biblioteca **`Vader`**:\n",
        "##### Como avaliar o resultado:\n",
        "- ##### Saída apresenta pontuação negativa, pontuação neutra, pontuação positiva, e o composto agregado, no qual uma pontuação maior do que 0,05 é considerada positiva, enquanto menor que -0,05 é considerada negativa."
      ],
      "metadata": {
        "id": "0a8BESnbDe4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ],
      "metadata": {
        "id": "NvWQ3zKwEIKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyser = SentimentIntensityAnalyzer()\n",
        "\n",
        "analyser.polarity_scores(\"I love pizza\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoFok6R7EO-e",
        "outputId": "69e0aa29-701e-4178-f10f-b7542b9cc725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'compound': 0.6369, 'neg': 0.0, 'neu': 0.323, 'pos': 0.677}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyser.polarity_scores(\"The weather is excellent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMXvcQtyEU8_",
        "outputId": "eda4d273-2470-4b18-8eb2-9ff3286e210b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'compound': 0.5719, 'neg': 0.0, 'neu': 0.448, 'pos': 0.552}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyser.polarity_scores(\"What a terrible thing to say\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uybAi9WIEU36",
        "outputId": "9e53753a-fc7f-4867-fd89-d72da15f0e9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'compound': -0.4767, 'neg': 0.383, 'neu': 0.617, 'pos': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Referências**\n",
        "\n",
        "- Comissão Especial de Processamento de Linguagem Natural (CE-PLN) https://sites.google.com/view/ce-pln/\n",
        "\n",
        "- Jurafsky, D. and Martin, J.H. (2008). Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics and Speech Recognition https://web.stanford.edu/~jurafsky/slp3/\n",
        "\n",
        "- NLTK Natural Language Toolkit https://www.nltk.org/\n",
        "\n",
        "- SpaCy https://spacy.io/\n",
        "\n",
        "- TextBlob https://textblob.readthedocs.io/en/dev/\n",
        "\n",
        "- VADER (Valence Aware Dictionary and Sentiment Reasoner) https://github.com/cjhutto/vaderSentiment"
      ],
      "metadata": {
        "id": "Y_COeZnKp7oo"
      }
    }
  ]
}